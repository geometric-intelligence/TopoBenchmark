_target_: topobenchmarkx.model.TBXModel

model_name: GraphMLP
model_domain: graph

feature_encoder:
  _target_: topobenchmarkx.nn.encoders.${model.feature_encoder.encoder_name}
  encoder_name: AllCellFeatureEncoder
  in_channels: ${infer_in_channels:${dataset},${oc.select:transforms,null}} 
  out_channels: 32
  proj_dropout: 0.0

backbone:
  _target_: topobenchmarkx.nn.backbones.GraphMLP
  in_channels: ${model.feature_encoder.out_channels}
  hidden_channels: ${model.feature_encoder.out_channels}
  order: 2
  dropout: 0.0
  loss:
    _target_: topobenchmarkx.loss.custom_losses.GraphMLPLoss
    r_adj_power: 2
    alpha: 1.
    tau: 1.

backbone_wrapper:
  _target_: topobenchmarkx.nn.wrappers.GraphMLPWrapper
  _partial_: true
  wrapper_name: GraphMLPWrapper
  out_channels: ${model.feature_encoder.out_channels}
  num_cell_dimensions: ${infere_num_cell_dimensions:${oc.select:model.feature_encoder.selected_dimensions,null},${model.feature_encoder.in_channels}}

readout:
  _target_: topobenchmarkx.nn.readouts.${model.readout.readout_name}
  readout_name: NoReadOut #  Use <NoReadOut> in case readout is not needed Options: PropagateSignalDown
  num_cell_dimensions: ${infere_num_cell_dimensions:${oc.select:model.feature_encoder.selected_dimensions,null},${model.feature_encoder.in_channels}} # The highest order of cell dimensions to consider
  hidden_dim: ${model.feature_encoder.out_channels}
  out_channels: ${dataset.parameters.num_classes}
  task_level: ${dataset.parameters.task_level}
  pooling_type: sum



# compile model for faster training with pytorch 2.0
compile: false
