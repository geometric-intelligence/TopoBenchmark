{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import ast\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"topobenchmark_22Apr2024\"  #'best_results_edhnn'\n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not needed (we shouldn't vary them or their variation is not interesting)\n",
    "remove_col = [\n",
    "    \"dataset.transforms.data_manipulations.selected_fields\",\n",
    "    \"callbacks.model_checkpoint.dirpath\",\n",
    "    \"dataset.transforms.infere_knn_connectivity.args.k\",\n",
    "    \"dataset.transforms.infere_knn_connectivity.args.loop\",\n",
    "    \"dataset.transforms.infere_knn_connectivity.args.cosine\",\n",
    "    \"dataset.transforms.infere_knn_connectivity._target_\",\n",
    "    \"dataset.transforms.infere_knn_connectivity.transform_type\",\n",
    "]\n",
    "for col in remove_col:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(col, axis=1)\n",
    "\n",
    "\n",
    "# Ensure that removed columns are not present in config_columns\n",
    "config_columns = [col for col in config_columns if col != remove_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36951/1961035444.py:1: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['dataset.transforms.infere_knn_connectivity.transform_name'][df['dataset.transforms.infere_knn_connectivity.transform_name']!='InfereKNNConnectivity'] = False\n",
      "/tmp/ipykernel_36951/1961035444.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['dataset.transforms.infere_knn_connectivity.transform_name'][df['dataset.transforms.infere_knn_connectivity.transform_name']!='InfereKNNConnectivity'] = False\n",
      "/tmp/ipykernel_36951/1961035444.py:2: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['dataset.transforms.infere_knn_connectivity.transform_name'][df['dataset.transforms.infere_knn_connectivity.transform_name']=='InfereKNNConnectivity'] = True\n",
      "/tmp/ipykernel_36951/1961035444.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['dataset.transforms.infere_knn_connectivity.transform_name'][df['dataset.transforms.infere_knn_connectivity.transform_name']=='InfereKNNConnectivity'] = True\n"
     ]
    }
   ],
   "source": [
    "df[\"dataset.transforms.infere_knn_connectivity.transform_name\"][\n",
    "    df[\"dataset.transforms.infere_knn_connectivity.transform_name\"]\n",
    "    != \"InfereKNNConnectivity\"\n",
    "] = False\n",
    "df[\"dataset.transforms.infere_knn_connectivity.transform_name\"][\n",
    "    df[\"dataset.transforms.infere_knn_connectivity.transform_name\"]\n",
    "    == \"InfereKNNConnectivity\"\n",
    "] = True\n",
    "\n",
    "df[\"Infere Connectivity\"] = df[\n",
    "    \"dataset.transforms.infere_knn_connectivity.transform_name\"\n",
    "]\n",
    "df = df.drop(\"dataset.transforms.infere_knn_connectivity.transform_name\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with model.backbone._target_ = nan is 7\n",
      "Number of rows with callbacks.early_stopping.monitor = nan is 0\n",
      "Because of SCCN and CWN false runs there were 96 such runs on 13/03/24\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Number of rows with model.backbone._target_ = nan is {sum(df['model.backbone._target_'].isna())}\"\n",
    ")\n",
    "# Drop na values if there are\n",
    "df = df.dropna(subset=[\"model.backbone._target_\"])\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Drop rows that 'callbacks.early_stopping.monitor' isna\n",
    "print(\n",
    "    f\"Number of rows with callbacks.early_stopping.monitor = nan is {sum(df['callbacks.early_stopping.monitor'].isna())}\"\n",
    ")\n",
    "print(\"Because of SCCN and CWN false runs there were 96 such runs on 13/03/24\")\n",
    "df = df.dropna(subset=[\"callbacks.early_stopping.monitor\"])\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Get correct names for the models\n",
    "df[\"model.backbone._target_\"] = df[\"model.backbone._target_\"].apply(\n",
    "    lambda x: x.split(\".\")[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "4827    False\n",
       "4828    False\n",
       "4829    False\n",
       "4830    False\n",
       "4831    False\n",
       "Name: Infere Connectivity, Length: 4832, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Infere Connectivity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.parameters.num_features, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on MUTAG:\n",
      "model.readout.in_channels: [64. 16.]\n",
      "\n",
      "model.backbone.n_layers: [2. 1.]\n",
      "\n",
      "model.backbone.in_channels_0: [64. 16.]\n",
      "\n",
      "model.backbone.in_channels_1: [64. 16.]\n",
      "\n",
      "model.backbone.in_channels_2: [64. 16.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.feature_encoder.out_channels: [64. 16.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [64. 16.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "dataset.parameters.batch_size: [16. 32.]\n",
      "\n",
      "Infere Connectivity: [False True]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.parameters.num_features, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on MUTAG:\n",
      "model.readout.in_channels: [256. 128.  64.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [256. 128.  64.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "dataset.parameters.batch_size: [64. 32.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on NCI1:\n",
      "model.readout.in_channels: [16. 64.]\n",
      "\n",
      "model.backbone.n_layers: [1. 2.]\n",
      "\n",
      "model.backbone.in_channels_0: [16. 64.]\n",
      "\n",
      "model.backbone.in_channels_1: [16. 64.]\n",
      "\n",
      "model.backbone.in_channels_2: [16. 64.]\n",
      "\n",
      "model.optimizer.lr: [0.01  0.001]\n",
      "\n",
      "model.feature_encoder.out_channels: [16. 64.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [16. 64.]\n",
      "\n",
      "dataset.parameters.data_seed: [3. 0. 5.]\n",
      "\n",
      "dataset.parameters.batch_size: [ 32. 128.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on NCI1:\n",
      "model.readout.in_channels: [256. 128.  64.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [256. 128.  64.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "dataset.parameters.batch_size: [256. 128.]\n",
      "\n",
      "Infere Connectivity: [False True]\n",
      "\n",
      "---------\n",
      "---------\n",
      "No results for SCN2 on REDDIT-BINARY\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on REDDIT-BINARY:\n",
      "model.readout.in_channels: [128.  64. 256.]\n",
      "\n",
      "model.optimizer.lr: [0.01  0.001]\n",
      "\n",
      "model.backbone.dropout: [0.   0.5  0.25]\n",
      "\n",
      "model.backbone.num_layers: [1. 4. 3. 2.]\n",
      "\n",
      "model.backbone.hidden_channels: [128.  64. 256.]\n",
      "\n",
      "dataset.parameters.data_seed: [0. 5. 3.]\n",
      "\n",
      "dataset.parameters.batch_size: [256. 128.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on ZINC:\n",
      "model.readout.in_channels: [16. 64.]\n",
      "\n",
      "model.backbone.n_layers: [1. 4. 2.]\n",
      "\n",
      "model.backbone.in_channels_0: [16. 64.]\n",
      "\n",
      "model.backbone.in_channels_1: [16. 64.]\n",
      "\n",
      "model.backbone.in_channels_2: [16. 64.]\n",
      "\n",
      "model.optimizer.lr: [0.01  0.001]\n",
      "\n",
      "model.feature_encoder.out_channels: [16. 64.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [16. 64.]\n",
      "\n",
      "dataset.parameters.data_seed: [0. 3.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on ZINC:\n",
      "model.readout.in_channels: [128.  64.  32.  16.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [128.  64.  32.  16.]\n",
      "\n",
      "dataset.parameters.batch_size: [256. 128.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on PROTEINS:\n",
      "model.readout.in_channels: [64. 16.]\n",
      "\n",
      "model.backbone.n_layers: [2. 1.]\n",
      "\n",
      "model.backbone.in_channels_0: [64. 16.]\n",
      "\n",
      "model.backbone.in_channels_1: [64. 16.]\n",
      "\n",
      "model.backbone.in_channels_2: [64. 16.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.feature_encoder.out_channels: [64. 16.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [64. 16.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "dataset.parameters.batch_size: [ 32. 128.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on PROTEINS:\n",
      "model.readout.in_channels: [256. 128.  64.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [256. 128.  64.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "dataset.parameters.batch_size: [256. 128.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on PubMed:\n",
      "model.readout.in_channels: [64. 32.]\n",
      "\n",
      "model.backbone.n_layers: [2. 1.]\n",
      "\n",
      "model.backbone.in_channels_0: [64. 32.]\n",
      "\n",
      "model.backbone.in_channels_1: [64. 32.]\n",
      "\n",
      "model.backbone.in_channels_2: [64. 32.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.feature_encoder.out_channels: [64. 32.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [64. 32.]\n",
      "\n",
      "dataset.parameters.data_seed: [3. 0. 5.]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on PubMed:\n",
      "model.readout.in_channels: [256. 128.  64.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [256. 128.  64.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on Cora:\n",
      "model.readout.in_channels: [64. 32.]\n",
      "\n",
      "model.backbone.n_layers: [2. 1.]\n",
      "\n",
      "model.backbone.in_channels_0: [64. 32.]\n",
      "\n",
      "model.backbone.in_channels_1: [64. 32.]\n",
      "\n",
      "model.backbone.in_channels_2: [64. 32.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.feature_encoder.out_channels: [64. 32.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [64. 32.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on Cora:\n",
      "model.readout.in_channels: [256. 128.  64.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [256. 128.  64.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: model.feature_encoder.selected_dimensions, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for SCN2 on citeseer:\n",
      "model.readout.in_channels: [64. 32.]\n",
      "\n",
      "model.backbone.n_layers: [2. 1.]\n",
      "\n",
      "model.backbone.in_channels_0: [64. 32.]\n",
      "\n",
      "model.backbone.in_channels_1: [64. 32.]\n",
      "\n",
      "model.backbone.in_channels_2: [64. 32.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.feature_encoder.out_channels: [64. 32.]\n",
      "\n",
      "model.backbone_wrapper.out_channels: [64. 32.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "---------\n",
      "Attention the columns: model.feature_encoder.in_channels, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.k, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.loop, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.args.cosine, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity._target_, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_name, has issues with unique values\n",
      "Attention the columns: dataset.transforms.infere_knn_connectivity.transform_type, has issues with unique values\n",
      "Attention the columns: callbacks.model_checkpoint.dirpath, has issues with unique values\n",
      "Unique values for each config column for GCN on citeseer:\n",
      "model.readout.in_channels: [256. 128.  64.]\n",
      "\n",
      "model.optimizer.lr: [0.001 0.01 ]\n",
      "\n",
      "model.backbone.dropout: [0.5  0.25 0.  ]\n",
      "\n",
      "model.backbone.num_layers: [4. 3. 2. 1.]\n",
      "\n",
      "model.backbone.hidden_channels: [256. 128.  64.]\n",
      "\n",
      "dataset.parameters.data_seed: [5. 3. 0.]\n",
      "\n",
      "Infere Connectivity: [True False]\n",
      "\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Identify unique models in DataFrame\n",
    "unique_models = df[\"model.backbone._target_\"].unique()\n",
    "\n",
    "# Identify unique datasets in DataFrame\n",
    "unique_datasets = df[\"dataset.parameters.data_name\"].unique()\n",
    "\n",
    "\n",
    "collected_results = defaultdict(dict)\n",
    "collected_aggregated_results = defaultdict(dict)\n",
    "collected_non_aggregated_results = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in unique_datasets:\n",
    "    for model in unique_models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df[\"dataset.parameters.data_name\"] == dataset)\n",
    "            & (df[\"model.backbone._target_\"] == model)\n",
    "        ]\n",
    "\n",
    "        if subset.empty:\n",
    "            print(f\"---------\")\n",
    "            print(f\"No results for {model} on {dataset}\")\n",
    "            print(f\"---------\")\n",
    "            continue\n",
    "        # Suppress all warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        subset[\"Model\"] = model\n",
    "        warnings.filterwarnings(\"default\")\n",
    "\n",
    "        def get_metric(df):\n",
    "            metric_ = df[\"callbacks.early_stopping.monitor\"].unique()\n",
    "            assert len(metric_) == 1, \"There should be only one metric to optimize\"\n",
    "            metric = metric_[0]\n",
    "            return metric.split(\"/\")[-1]\n",
    "\n",
    "        # Cols to get statistics later\n",
    "        performance_cols = [f\"val/{get_metric(subset)}\", f\"test/{get_metric(subset)}\"]\n",
    "\n",
    "        # Get the unique values for each config column\n",
    "        unique_colums_values = {}\n",
    "        for col in config_columns + [\"Infere Connectivity\"]:\n",
    "            try:\n",
    "                unique_colums_values[col] = subset[col].unique()\n",
    "            except:\n",
    "                print(f\"Attention the columns: {col}, has issues with unique values\")\n",
    "\n",
    "        # Keep only those keys that have more than one unique value\n",
    "        unique_colums_values = {\n",
    "            k: v for k, v in unique_colums_values.items() if len(v) > 1\n",
    "        }\n",
    "\n",
    "        # Print the unique values for each config column\n",
    "\n",
    "        print(f\"Unique values for each config column for {model} on {dataset}:\")\n",
    "        for col, unique in unique_colums_values.items():\n",
    "            print(f\"{col}: {unique}\")\n",
    "            print()\n",
    "        print(f\"---------\")\n",
    "\n",
    "        # Check if \"special colums\" are not in unique_colums_values\n",
    "        # For example dataset.parameters.data_seed should not be in aggregation columns\n",
    "        # If it is, then we should remove it from the list\n",
    "        special_columns = [\"dataset.parameters.data_seed\"]\n",
    "\n",
    "        for col in special_columns:\n",
    "            if col in unique_colums_values:\n",
    "                unique_colums_values.pop(col)\n",
    "\n",
    "        # Obtain the aggregation columns\n",
    "        aggregation_columns = [\"Model\"] + list(unique_colums_values.keys())\n",
    "\n",
    "        # Check if there if \"Infere Connectivity\" if not add it to aggregation columns\n",
    "        if \"Infere Connectivity\" not in aggregation_columns:\n",
    "            aggregation_columns.append(\"Infere Connectivity\")\n",
    "\n",
    "        collected_non_aggregated_results[dataset][model] = {\n",
    "            \"df\": subset.copy(),\n",
    "            \"aggregation_columns\": aggregation_columns,\n",
    "            \"performance_cols\": performance_cols,\n",
    "        }\n",
    "\n",
    "        # Aggregate the subset by the aggregation columns and get the best result for each group\n",
    "        aggregated = subset.groupby(aggregation_columns).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_cols}\n",
    "        )\n",
    "\n",
    "        # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "\n",
    "        assert (\n",
    "            len(subset[\"callbacks.early_stopping.mode\"].unique()) == 1\n",
    "        ), \"There should be only one mode for early stopping\"\n",
    "        # Identify the mode of the early stopping mode\n",
    "\n",
    "        # Find best results with respect to the validation set\n",
    "        if subset[\"callbacks.early_stopping.mode\"].unique()[0] == \"max\":\n",
    "            ascending = False\n",
    "            final_best_ = aggregated.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "            final_best_ = (final_best_ * 100).round(2)\n",
    "        else:\n",
    "            ascending = True\n",
    "            final_best_ = aggregated.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "\n",
    "        # Get the best with respect to test set\n",
    "        collected_results[dataset][model] = {\n",
    "            \"mean\": final_best_[(f\"test/{get_metric(subset)}\", \"mean\")].values[0],\n",
    "            \"std\": final_best_[(f\"test/{get_metric(subset)}\", \"std\")].values[0],\n",
    "        }\n",
    "        collected_aggregated_results[dataset][model] = aggregated.sort_values(\n",
    "            by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "        )\n",
    "\n",
    "    #  break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>val/accuracy</th>\n",
       "      <th>trainer/global_step</th>\n",
       "      <th>_step</th>\n",
       "      <th>_wandb</th>\n",
       "      <th>lr-Adam</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>...</th>\n",
       "      <th>callbacks.model_checkpoint.every_n_epochs</th>\n",
       "      <th>callbacks.model_checkpoint.save_weights_only</th>\n",
       "      <th>callbacks.model_checkpoint.every_n_train_steps</th>\n",
       "      <th>callbacks.model_checkpoint.train_time_interval</th>\n",
       "      <th>callbacks.model_checkpoint.auto_insert_metric_name</th>\n",
       "      <th>callbacks.model_checkpoint.save_on_train_epoch_end</th>\n",
       "      <th>callbacks.rich_progress_bar._target_</th>\n",
       "      <th>callbacks.learning_rate_monitor._target_</th>\n",
       "      <th>callbacks.learning_rate_monitor.logging_interval</th>\n",
       "      <th>Infere Connectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.440755</td>\n",
       "      <td>1.714498e+09</td>\n",
       "      <td>0.344573</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>570.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>{'runtime': 9}</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>11.146549</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.698719</td>\n",
       "      <td>1.714498e+09</td>\n",
       "      <td>0.250919</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>780.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>{'runtime': 11}</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>13.230936</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>1.714498e+09</td>\n",
       "      <td>0.332483</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>600.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>{'runtime': 9}</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>11.107776</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.424564</td>\n",
       "      <td>1.714498e+09</td>\n",
       "      <td>0.298073</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>780.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>{'runtime': 11}</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>13.186315</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.591233</td>\n",
       "      <td>1.714498e+09</td>\n",
       "      <td>0.316741</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>420.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>{'runtime': 6}</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>8.108738</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.160258</td>\n",
       "      <td>1.714195e+09</td>\n",
       "      <td>0.227150</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>180.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>{'runtime': 13}</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>15.043748</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.701639</td>\n",
       "      <td>1.714195e+09</td>\n",
       "      <td>0.314709</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>240.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>{'runtime': 17}</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>18.072189</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.421848</td>\n",
       "      <td>1.714195e+09</td>\n",
       "      <td>0.286058</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>315.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>{'runtime': 21}</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>22.765034</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.818408</td>\n",
       "      <td>1.714195e+09</td>\n",
       "      <td>0.283608</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>225.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>{'runtime': 15}</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>16.458794</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.631320</td>\n",
       "      <td>1.714195e+09</td>\n",
       "      <td>0.277067</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>300.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>{'runtime': 20}</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>21.385238</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.RichProgressBar</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  val/loss    _timestamp  train/loss  val/accuracy  \\\n",
       "0      95.0  0.440755  1.714498e+09    0.344573      0.829787   \n",
       "1     130.0  0.698719  1.714498e+09    0.250919      0.765957   \n",
       "2     100.0  0.571365  1.714498e+09    0.332483      0.659574   \n",
       "3     130.0  0.424564  1.714498e+09    0.298073      0.744681   \n",
       "4      70.0  0.591233  1.714498e+09    0.316741      0.723404   \n",
       "...     ...       ...           ...         ...           ...   \n",
       "1426   60.0  1.160258  1.714195e+09    0.227150      0.808511   \n",
       "1427   80.0  0.701639  1.714195e+09    0.314709      0.702128   \n",
       "1429  105.0  0.421848  1.714195e+09    0.286058      0.787234   \n",
       "1430   75.0  0.818408  1.714195e+09    0.283608      0.744681   \n",
       "1431  100.0  0.631320  1.714195e+09    0.277067      0.744681   \n",
       "\n",
       "      trainer/global_step  _step           _wandb   lr-Adam   _runtime  ...  \\\n",
       "0                   570.0  209.0   {'runtime': 9}  0.000731  11.146549  ...   \n",
       "1                   780.0  286.0  {'runtime': 11}  0.000631  13.230936  ...   \n",
       "2                   600.0  220.0   {'runtime': 9}  0.000717  11.107776  ...   \n",
       "3                   780.0  286.0  {'runtime': 11}  0.000631  13.186315  ...   \n",
       "4                   420.0  154.0   {'runtime': 6}  0.000803   8.108738  ...   \n",
       "...                   ...    ...              ...       ...        ...  ...   \n",
       "1426                180.0  132.0  {'runtime': 13}  0.008314  15.043748  ...   \n",
       "1427                240.0  176.0  {'runtime': 17}  0.007743  18.072189  ...   \n",
       "1429                315.0  231.0  {'runtime': 21}  0.007029  22.765034  ...   \n",
       "1430                225.0  165.0  {'runtime': 15}  0.007886  16.458794  ...   \n",
       "1431                300.0  220.0  {'runtime': 20}  0.007171  21.385238  ...   \n",
       "\n",
       "      callbacks.model_checkpoint.every_n_epochs  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "...                                         ...   \n",
       "1426                                        NaN   \n",
       "1427                                        NaN   \n",
       "1429                                        NaN   \n",
       "1430                                        NaN   \n",
       "1431                                        NaN   \n",
       "\n",
       "      callbacks.model_checkpoint.save_weights_only  \\\n",
       "0                                            False   \n",
       "1                                            False   \n",
       "2                                            False   \n",
       "3                                            False   \n",
       "4                                            False   \n",
       "...                                            ...   \n",
       "1426                                         False   \n",
       "1427                                         False   \n",
       "1429                                         False   \n",
       "1430                                         False   \n",
       "1431                                         False   \n",
       "\n",
       "      callbacks.model_checkpoint.every_n_train_steps  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "1426                                             NaN   \n",
       "1427                                             NaN   \n",
       "1429                                             NaN   \n",
       "1430                                             NaN   \n",
       "1431                                             NaN   \n",
       "\n",
       "      callbacks.model_checkpoint.train_time_interval  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "1426                                             NaN   \n",
       "1427                                             NaN   \n",
       "1429                                             NaN   \n",
       "1430                                             NaN   \n",
       "1431                                             NaN   \n",
       "\n",
       "     callbacks.model_checkpoint.auto_insert_metric_name  \\\n",
       "0                                                 False   \n",
       "1                                                 False   \n",
       "2                                                 False   \n",
       "3                                                 False   \n",
       "4                                                 False   \n",
       "...                                                 ...   \n",
       "1426                                              False   \n",
       "1427                                              False   \n",
       "1429                                              False   \n",
       "1430                                              False   \n",
       "1431                                              False   \n",
       "\n",
       "     callbacks.model_checkpoint.save_on_train_epoch_end  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1426                                                NaN   \n",
       "1427                                                NaN   \n",
       "1429                                                NaN   \n",
       "1430                                                NaN   \n",
       "1431                                                NaN   \n",
       "\n",
       "             callbacks.rich_progress_bar._target_  \\\n",
       "0     lightning.pytorch.callbacks.RichProgressBar   \n",
       "1     lightning.pytorch.callbacks.RichProgressBar   \n",
       "2     lightning.pytorch.callbacks.RichProgressBar   \n",
       "3     lightning.pytorch.callbacks.RichProgressBar   \n",
       "4     lightning.pytorch.callbacks.RichProgressBar   \n",
       "...                                           ...   \n",
       "1426  lightning.pytorch.callbacks.RichProgressBar   \n",
       "1427  lightning.pytorch.callbacks.RichProgressBar   \n",
       "1429  lightning.pytorch.callbacks.RichProgressBar   \n",
       "1430  lightning.pytorch.callbacks.RichProgressBar   \n",
       "1431  lightning.pytorch.callbacks.RichProgressBar   \n",
       "\n",
       "             callbacks.learning_rate_monitor._target_  \\\n",
       "0     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "1     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "2     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "3     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "4     lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "...                                               ...   \n",
       "1426  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "1427  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "1429  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "1430  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "1431  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "\n",
       "     callbacks.learning_rate_monitor.logging_interval  Infere Connectivity  \n",
       "0                                               epoch                False  \n",
       "1                                               epoch                False  \n",
       "2                                               epoch                False  \n",
       "3                                               epoch                False  \n",
       "4                                               epoch                False  \n",
       "...                                               ...                  ...  \n",
       "1426                                            epoch                 True  \n",
       "1427                                            epoch                 True  \n",
       "1429                                            epoch                 True  \n",
       "1430                                            epoch                 True  \n",
       "1431                                            epoch                 True  \n",
       "\n",
       "[72 rows x 132 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\n",
    "    (df[\"dataset.parameters.data_name\"] == \"MUTAG\")\n",
    "    & (df[\"model.backbone._target_\"] == \"SCN2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_results_inferred_connectivity = defaultdict(dict)\n",
    "\n",
    "# Get the best result for each dataset and model for InfereKNNConnectivity case\n",
    "for dataset in [\n",
    "    \"MUTAG\",\n",
    "    \"REDDIT-BINARY\",\n",
    "    \"NCI1\",\n",
    "    \"PROTEINS\",\n",
    "    \"PubMed\",\n",
    "    \"Cora\",\n",
    "    \"citeseer\",\n",
    "]:\n",
    "    for model in collected_aggregated_results[dataset].keys():\n",
    "        # try:\n",
    "\n",
    "        col_name = \"Infere Connectivity\"\n",
    "        a = collected_aggregated_results[dataset][model]\n",
    "\n",
    "        a = a[a[col_name] == True]\n",
    "\n",
    "        # Check if there are any results\n",
    "        if a.empty:\n",
    "            continue\n",
    "\n",
    "        if subset[\"callbacks.early_stopping.mode\"].unique()[0] == \"max\":\n",
    "            ascending = False\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "            final_best_ = (final_best_ * 100).round(2)\n",
    "        else:\n",
    "            ascending = True\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "\n",
    "        collected_results_inferred_connectivity[dataset][model] = {\n",
    "            \"mean\": final_best_[(f\"test/{get_metric(subset)}\", \"mean\")].values[0],\n",
    "            \"std\": final_best_[(f\"test/{get_metric(subset)}\", \"std\")].values[0],\n",
    "        }\n",
    "        # except:\n",
    "        #     pass\n",
    "\n",
    "collected_results_original_connectivity = defaultdict(dict)\n",
    "# Get the best result for each dataset and model for classical case\n",
    "for dataset in [\n",
    "    \"REDDIT-BINARY\",\n",
    "    \"MUTAG\",\n",
    "    \"NCI1\",\n",
    "    \"PROTEINS\",\n",
    "    \"PubMed\",\n",
    "    \"Cora\",\n",
    "    \"citeseer\",\n",
    "]:\n",
    "    for model in collected_aggregated_results[dataset].keys():\n",
    "        # try:\n",
    "\n",
    "        col_name = \"Infere Connectivity\"\n",
    "        a = collected_aggregated_results[dataset][model]\n",
    "\n",
    "        a = a[a[col_name] == False]\n",
    "\n",
    "        # Check if there are any results\n",
    "        if a.empty:\n",
    "            continue\n",
    "\n",
    "        if subset[\"callbacks.early_stopping.mode\"].unique()[0] == \"max\":\n",
    "            ascending = False\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "            final_best_ = (final_best_ * 100).round(2)\n",
    "        else:\n",
    "            ascending = True\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "\n",
    "        collected_results_original_connectivity[dataset][model] = {\n",
    "            \"mean\": final_best_[(f\"test/{get_metric(subset)}\", \"mean\")].values[0],\n",
    "            \"std\": final_best_[(f\"test/{get_metric(subset)}\", \"std\")].values[0],\n",
    "        }\n",
    "        # except:\n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>REDDIT-BINARY</th>\n",
       "      <th>citeseer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>87.2  1.2</td>\n",
       "      <td>77.3  2.46</td>\n",
       "      <td>74.19  1.22</td>\n",
       "      <td>75.27  2.8</td>\n",
       "      <td>79.53  1.4</td>\n",
       "      <td>72.11  1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCN2</th>\n",
       "      <td>84.79  1.15</td>\n",
       "      <td>78.72  2.13</td>\n",
       "      <td>74.29  1.44</td>\n",
       "      <td>76.46  1.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.31  2.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Cora         MUTAG          NCI1      PROTEINS REDDIT-BINARY  \\\n",
       "Model                                                                           \n",
       "GCN        87.2  1.2   77.3  2.46  74.19  1.22   75.27  2.8   79.53  1.4   \n",
       "SCN2     84.79  1.15  78.72  2.13  74.29  1.44  76.46  1.77           NaN   \n",
       "\n",
       "Dataset      citeseer  \n",
       "Model                  \n",
       "GCN      72.11  1.75  \n",
       "SCN2     73.31  2.55  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(collected_results_original_connectivity)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict.keys()\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "\n",
    "result_dict = result_dict.round(2)\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>REDDIT-BINARY</th>\n",
       "      <th>citeseer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>67.65  0.82</td>\n",
       "      <td>80.14  4.43</td>\n",
       "      <td>68.84  1.38</td>\n",
       "      <td>74.79  1.36</td>\n",
       "      <td>81.59  0.28</td>\n",
       "      <td>76.13  0.81</td>\n",
       "      <td>56.46  1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCN2</th>\n",
       "      <td>64.3  3.55</td>\n",
       "      <td>80.14  3.25</td>\n",
       "      <td>66.93  nan</td>\n",
       "      <td>75.63  1.86</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Cora         MUTAG          NCI1      PROTEINS        PubMed  \\\n",
       "Model                                                                           \n",
       "GCN      67.65  0.82  80.14  4.43  68.84  1.38  74.79  1.36  81.59  0.28   \n",
       "SCN2      64.3  3.55  80.14  3.25   66.93  nan  75.63  1.86     nan  nan   \n",
       "\n",
       "Dataset REDDIT-BINARY      citeseer  \n",
       "Model                                \n",
       "GCN      76.13  0.81  56.46  1.53  \n",
       "SCN2              NaN           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(collected_results_inferred_connectivity)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict.keys()\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "\n",
    "result_dict = result_dict.round(2)\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cora\n",
    "GCN 87.2  1.2\n",
    "SCN 84.79  1.15\n",
    "\n",
    "Cora (KNN)\n",
    "GCN 67.65  0.82\n",
    "SCN 64.3  3.55\n",
    "\n",
    "PROTEINS\n",
    "GCN 75.27  2.8\n",
    "SCN 76.46  1.77\n",
    "\n",
    "PROTEINS (KNN)\n",
    "GCN 74.79  1.36\n",
    "SCN 75.63  1.86\n",
    "\n",
    "NCI1\n",
    "74.19  1.22\n",
    "74.29  1.44\n",
    "\n",
    "NCI1 (KNN)\n",
    "GCN 68.84  1.38\n",
    "SCN --  --\n",
    "\n",
    "\n",
    "Mutag\n",
    "GCN 77.3  2.46\n",
    "SCN 78.72  2.13\n",
    "\n",
    "Mutag (KNN)\n",
    "GCN 80.14  4.43\n",
    "SCN 80.14  3.25\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_results_inferred_connectivity = defaultdict(dict)\n",
    "\n",
    "# Get the best result for each dataset and model for InfereKNNConnectivity case\n",
    "for dataset in [\n",
    "    \"MUTAG\",\n",
    "    \"REDDIT-BINARY\",\n",
    "    \"NCI1\",\n",
    "    \"PROTEINS\",\n",
    "    \"PubMed\",\n",
    "    \"Cora\",\n",
    "    \"citeseer\",\n",
    "]:\n",
    "    for model in collected_aggregated_results[dataset].keys():\n",
    "        # try:\n",
    "\n",
    "        col_name = \"Infere Connectivity\"\n",
    "        a = collected_aggregated_results[dataset][model]\n",
    "\n",
    "        a = a[a[col_name] == True]\n",
    "\n",
    "        # Check if there are any results\n",
    "        if a.empty:\n",
    "            continue\n",
    "\n",
    "        if subset[\"callbacks.early_stopping.mode\"].unique()[0] == \"max\":\n",
    "            ascending = False\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "            final_best_ = (final_best_ * 100).round(2)\n",
    "        else:\n",
    "            ascending = True\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "\n",
    "        collected_results_inferred_connectivity[dataset][model] = {\n",
    "            \"mean\": final_best_[(f\"test/{get_metric(subset)}\", \"mean\")].values[0],\n",
    "            \"std\": final_best_[(f\"test/{get_metric(subset)}\", \"std\")].values[0],\n",
    "        }\n",
    "        # except:\n",
    "        #     pass\n",
    "\n",
    "collected_results_original_connectivity = defaultdict(dict)\n",
    "# Get the best result for each dataset and model for classical case\n",
    "for dataset in [\n",
    "    \"REDDIT-BINARY\",\n",
    "    \"MUTAG\",\n",
    "    \"NCI1\",\n",
    "    \"PROTEINS\",\n",
    "    \"PubMed\",\n",
    "    \"Cora\",\n",
    "    \"citeseer\",\n",
    "]:\n",
    "    for model in collected_aggregated_results[dataset].keys():\n",
    "        # try:\n",
    "\n",
    "        col_name = \"Infere Connectivity\"\n",
    "        a = collected_aggregated_results[dataset][model]\n",
    "\n",
    "        a = a[a[col_name] == False]\n",
    "\n",
    "        # Check if there are any results\n",
    "        if a.empty:\n",
    "            continue\n",
    "\n",
    "        if subset[\"callbacks.early_stopping.mode\"].unique()[0] == \"max\":\n",
    "            ascending = False\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "            final_best_ = (final_best_ * 100).round(2)\n",
    "        else:\n",
    "            ascending = True\n",
    "            final_best_ = a.sort_values(\n",
    "                by=(f\"val/{get_metric(subset)}\", \"mean\"), ascending=ascending\n",
    "            ).head(1)\n",
    "\n",
    "        collected_results_original_connectivity[dataset][model] = {\n",
    "            \"mean\": final_best_[(f\"test/{get_metric(subset)}\", \"mean\")].values[0],\n",
    "            \"std\": final_best_[(f\"test/{get_metric(subset)}\", \"std\")].values[0],\n",
    "        }\n",
    "        # except:\n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
