{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Cellular\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models that have finished the runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lr-Adam', 'val/recall', 'train/accuracy', 'train/precision', 'epoch']\n",
      "['_runtime', 'train/loss', 'val/precision', '_step', 'val/auroc']\n",
      "['_timestamp', 'train/auroc', 'train/recall', 'trainer/global_step', 'val/loss']\n",
      "['val/accuracy', 'seed', 'tags', 'extras', 'trainer']\n",
      "['ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable', 'model/params/non_trainable']\n",
      "['test/accuracy', 'test/precision', '_wandb', 'test/auroc', 'test/recall']\n",
      "['test/loss', 'val/mae', 'test/mse', 'val/mse', 'test/mae']\n",
      "['train/mae', 'train/mse', 'epoch_run_time', 'model.compile', 'model._target_']\n",
      "['model.model_name', 'model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type']\n",
      "['model.readout._target_', 'model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone.dropout']\n",
      "['model.backbone._target_', 'model.backbone.n_layers', 'model.backbone.in_channels', 'model.optimizer.lr', 'model.optimizer._target_']\n",
      "['model.optimizer._partial_', 'model.optimizer.weight_decay', 'model.scheduler.gamma', 'model.scheduler._target_', 'model.scheduler._partial_']\n",
      "['model.scheduler.step_size', 'model.head_model._target_', 'model.head_model.task_level', 'model.head_model.in_channels', 'model.head_model.out_channels']\n",
      "['model.head_model.pooling_type', 'model.head_model.head_model_name', 'model.feature_encoder._target_', 'model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name']\n",
      "['model.feature_encoder.out_channels', 'model.feature_encoder.proj_dropout', 'model.feature_encoder.selected_dimensions', 'model.backbone_wrapper._target_', 'model.backbone_wrapper._partial_']\n",
      "['model.backbone_wrapper.out_channels', 'model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.att', 'model.backbone.in_channels_0']\n",
      "['model.backbone.in_channels_1', 'model.backbone.in_channels_2', 'model.backbone_additional_params.hidden_channels', 'model.backbone.hid_channels', 'dataset._target_']\n",
      "['dataset.parameters.k', 'dataset.parameters.task', 'dataset.parameters.data_dir', 'dataset.parameters.data_name', 'dataset.parameters.data_seed']\n",
      "['dataset.parameters.data_type', 'dataset.parameters.loss_type', 'dataset.parameters.batch_size', 'dataset.parameters.pin_memory', 'dataset.parameters.split_type']\n",
      "['dataset.parameters.task_level', 'dataset.parameters.train_prop', 'dataset.parameters.data_domain', 'dataset.parameters.num_classes', 'dataset.parameters.num_workers']\n",
      "['dataset.parameters.num_features', 'dataset.parameters.data_split_dir', 'dataset.parameters.max_x_1_degree', 'dataset.parameters.monitor_metric', 'dataset.parameters.max_node_degree']\n",
      "['dataset.transforms.data_manipulations._target_', 'dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type', 'dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.graph2cell_lifting._target_']\n",
      "['dataset.transforms.graph2cell_lifting.complex_dim', 'dataset.transforms.graph2cell_lifting.transform_name', 'dataset.transforms.graph2cell_lifting.transform_type', 'dataset.transforms.graph2cell_lifting.max_cell_length', 'dataset.transforms.graph2cell_lifting.preserve_edge_attr']\n",
      "['dataset.transforms.one_hot_node_degree_features._target_', 'dataset.transforms.one_hot_node_degree_features.max_degree', 'dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type']\n",
      "['dataset.transforms.one_hot_node_degree_features.features_fields', 'dataset.parameters.force_reload', 'dataset.parameters.year', 'dataset.parameters.task_variable', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n",
      "['dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted', 'callbacks.model_summary._target_', 'callbacks.model_summary.max_depth', 'callbacks.early_stopping.mode']\n",
      "['callbacks.early_stopping.strict', 'callbacks.early_stopping.monitor', 'callbacks.early_stopping.verbose', 'callbacks.early_stopping._target_', 'callbacks.early_stopping.patience']\n",
      "['callbacks.early_stopping.min_delta', 'callbacks.early_stopping.check_finite', 'callbacks.early_stopping.stopping_threshold', 'callbacks.early_stopping.divergence_threshold', 'callbacks.early_stopping.check_on_train_epoch_end']\n",
      "['callbacks.model_checkpoint.mode', 'callbacks.model_checkpoint.dirpath', 'callbacks.model_checkpoint.monitor', 'callbacks.model_checkpoint.verbose', 'callbacks.model_checkpoint._target_']\n",
      "['callbacks.model_checkpoint.filename', 'callbacks.model_checkpoint.save_last', 'callbacks.model_checkpoint.save_top_k', 'callbacks.model_checkpoint.every_n_epochs', 'callbacks.model_checkpoint.save_weights_only']\n",
      "['callbacks.model_checkpoint.every_n_train_steps', 'callbacks.model_checkpoint.train_time_interval', 'callbacks.model_checkpoint.auto_insert_metric_name', 'callbacks.model_checkpoint.save_on_train_epoch_end', 'callbacks.rich_progress_bar._target_']\n",
      "['callbacks.learning_rate_monitor._target_', 'callbacks.learning_rate_monitor.logging_interval', 'paths.log_dir', 'paths.data_dir', 'paths.root_dir']\n",
      "['paths.work_dir', 'paths.output_dir']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMDB-MULTI' 'minesweeper' 'US-county-demos-BachelorRate' 'ZINC'\n",
      " 'US-county-demos-DeathRate' 'PROTEINS' 'US-county-demos-BirthRate'\n",
      " 'IMDB-BINARY' nan 'MUTAG' 'US-county-demos-MigraRate' 'PubMed'\n",
      " 'roman_empire' 'citeseer' 'Cora' 'US-county-demos-UnemploymentRate'\n",
      " 'US-county-demos-MedianIncome' 'US-county-demos-Election']\n",
      "Num unique datasets: 18\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cwn_dcm' 'ccxn' 'cwn' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: cwn_dcm\n",
      "[1.]\n",
      "[1.]\n",
      "MODEL: ccxn\n",
      "[]\n",
      "[]\n",
      "MODEL: cwn\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['minesweeper', 'roman_empire']\n",
    "models = ['cwn_dcm', 'ccxn', 'cwn']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    print(\"MODEL:\", model)\n",
    "    for dataset in datasets:\n",
    "\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        \n",
    "        print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), 'dataset.parameters.batch_size'].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.5   nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: cwn_dcm\n",
      "Dataset: IMDB-MULTI\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32. 128.  64.]\n",
      "Column: model.backbone.n_layers\n",
      "[1. 4. 3. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[3. 2. 1. 4.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.01  0.001]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1. 4. 3.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64.  32. 128.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[ 42. 150.  23.   3.   5.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0. 3. 9. 7. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: ccxn\n",
      "Dataset: IMDB-MULTI\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.01  0.001]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 4.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[ 5.  3. 42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: cwn\n",
      "Dataset: IMDB-MULTI\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[150.  23.   5.   3.  42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: IMDB-BINARY\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n"
     ]
    }
   ],
   "source": [
    "# Sweeped parameters: \n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'dataset.parameters.data_seed',\n",
    "    'seed',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "for model in df['model.model_name'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in df['dataset.parameters.data_name'].unique():\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for column in sweeped_columns:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "        print('---------------NEW DATASET------------------')\n",
    "    print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    # 'dataset.parameters.data_seed',\n",
    "    # 'seed',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mse', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-BachelorRate, Model: ccxn\n",
      "Total rows in subset: 460\n",
      "Total dropped rows: 25\n",
      "Dropping rows with NaN values\n",
      "Dataset: ZINC, Model: ccxn\n",
      "Total rows in subset: 231\n",
      "Total dropped rows: 27\n",
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-DeathRate, Model: ccxn\n",
      "Total rows in subset: 465\n",
      "Total dropped rows: 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-BirthRate, Model: ccxn\n",
      "Total rows in subset: 459\n",
      "Total dropped rows: 45\n",
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-MigraRate, Model: ccxn\n",
      "Total rows in subset: 432\n",
      "Total dropped rows: 31\n",
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: ccxn\n",
      "Total rows in subset: 474\n",
      "Total dropped rows: 40\n",
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-MedianIncome, Model: ccxn\n",
      "Total rows in subset: 450\n",
      "Total dropped rows: 37\n",
      "Dropping rows with NaN values\n",
      "Dataset: US-county-demos-Election, Model: ccxn\n",
      "Total rows in subset: 457\n",
      "Total dropped rows: 40\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan\n",
    "            # If there are any 'NaN' string in the column print the column name and the number of 'NaN' strings\n",
    "            \n",
    "\n",
    "        if total_performance_nan > 0:\n",
    "            print('Dropping rows with NaN values')\n",
    "            print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "            print('Total rows in subset:', nan_rows.shape[0])\n",
    "            print('Total dropped rows:', sum(nan_rows.gt(0)))\n",
    "    \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "        # Aggregate\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns},\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        if final_best[(eval_metric, \"mean\")].any(): \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "            }\n",
    "\n",
    "            # Extract best runs: \n",
    "            best_params = {}\n",
    "            for col in sweeped_columns:\n",
    "                best_params[col] = final_best[(col, '')].item()\n",
    "            \n",
    "            hp_runs[dataset][model] = subset.copy()\n",
    "            \n",
    "            # Start with the entire DataFrame\n",
    "            filtered_subset = subset.copy()\n",
    "\n",
    "            # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "            for param, value in best_params.items():\n",
    "                filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "            best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "        else: \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": np.nan,\n",
    "                \"std\": np.nan,\n",
    "            }\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>dataset.parameters.data_name</th>\n",
       "      <th>model.optimizer.lr</th>\n",
       "      <th>model.feature_encoder.out_channels</th>\n",
       "      <th>model.backbone.n_layers</th>\n",
       "      <th>model.readout.readout_name</th>\n",
       "      <th>model.feature_encoder.proj_dropout</th>\n",
       "      <th>dataset.parameters.batch_size</th>\n",
       "      <th>val/mae</th>\n",
       "      <th>test/mae</th>\n",
       "      <th>val/mse</th>\n",
       "      <th>test/mse</th>\n",
       "      <th>dataset.parameters.data_seed</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11895</th>\n",
       "      <td>ccxn</td>\n",
       "      <td>US-county-demos-DeathRate</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531041</td>\n",
       "      <td>0.585732</td>\n",
       "      <td>0.514145</td>\n",
       "      <td>0.619329</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model.model_name dataset.parameters.data_name  model.optimizer.lr  model.feature_encoder.out_channels  model.backbone.n_layers model.readout.readout_name  model.feature_encoder.proj_dropout  dataset.parameters.batch_size   val/mae  test/mae   val/mse  test/mse  dataset.parameters.data_seed  seed\n",
       "11895             ccxn    US-county-demos-DeathRate                0.01                               128.0                      4.0        PropagateSignalDown                                 0.5                            1.0  0.531041  0.585732  0.514145  0.619329                           7.0  42.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_runs['US-county-demos-DeathRate']['ccxn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>IMDB-BINARY</th>\n",
       "      <th>IMDB-MULTI</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ccxn</th>\n",
       "      <td>86.79  1.81</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>74.89  5.51</td>\n",
       "      <td>75.63  2.57</td>\n",
       "      <td>88.91  0.47</td>\n",
       "      <td>0.3166  0.0288</td>\n",
       "      <td>0.715  0.0666</td>\n",
       "      <td>0.6193  nan</td>\n",
       "      <td>0.3471  0.0154</td>\n",
       "      <td>0.2489  0.0296</td>\n",
       "      <td>0.8482  0.185</td>\n",
       "      <td>0.2707  0.0258</td>\n",
       "      <td>0.4187  0.0228</td>\n",
       "      <td>74.67  2.24</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>nan  nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cwn</th>\n",
       "      <td>86.32  1.38</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>80.43  1.78</td>\n",
       "      <td>76.13  2.7</td>\n",
       "      <td>88.64  0.36</td>\n",
       "      <td>0.3306  0.0279</td>\n",
       "      <td>0.7181  0.086</td>\n",
       "      <td>0.5399  0.0553</td>\n",
       "      <td>0.3437  0.0216</td>\n",
       "      <td>0.2468  0.03</td>\n",
       "      <td>0.838  0.1286</td>\n",
       "      <td>0.2535  0.031</td>\n",
       "      <td>0.3497  0.012</td>\n",
       "      <td>75.2  1.82</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>nan  nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cwn_dcm</th>\n",
       "      <td>87.44  1.35</td>\n",
       "      <td>69.12  2.82</td>\n",
       "      <td>47.79  3.45</td>\n",
       "      <td>77.02  9.32</td>\n",
       "      <td>73.33  2.3</td>\n",
       "      <td>88.62  0.4</td>\n",
       "      <td>0.3227  0.0338</td>\n",
       "      <td>0.7134  0.0915</td>\n",
       "      <td>0.5443  0.0568</td>\n",
       "      <td>0.307  0.0155</td>\n",
       "      <td>0.2263  0.0187</td>\n",
       "      <td>0.8373  0.1206</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>0.4089  0.0128</td>\n",
       "      <td>75.63  1.67</td>\n",
       "      <td>89.42  0.0</td>\n",
       "      <td>82.14  0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Cora   IMDB-BINARY    IMDB-MULTI         MUTAG      PROTEINS  \\\n",
       "Model                                                                           \n",
       "ccxn     86.79  1.81     nan  nan     nan  nan  74.89  5.51  75.63  2.57   \n",
       "cwn      86.32  1.38     nan  nan     nan  nan  80.43  1.78   76.13  2.7   \n",
       "cwn_dcm  87.44  1.35  69.12  2.82  47.79  3.45  77.02  9.32   73.33  2.3   \n",
       "\n",
       "Dataset        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate  \\\n",
       "Model                                                                          \n",
       "ccxn     88.91  0.47              0.3166  0.0288            0.715  0.0666   \n",
       "cwn      88.64  0.36              0.3306  0.0279            0.7181  0.086   \n",
       "cwn_dcm   88.62  0.4              0.3227  0.0338           0.7134  0.0915   \n",
       "\n",
       "Dataset US-county-demos-DeathRate US-county-demos-Election  \\\n",
       "Model                                                        \n",
       "ccxn                 0.6193  nan          0.3471  0.0154   \n",
       "cwn               0.5399  0.0553          0.3437  0.0216   \n",
       "cwn_dcm           0.5443  0.0568           0.307  0.0155   \n",
       "\n",
       "Dataset US-county-demos-MedianIncome US-county-demos-MigraRate  \\\n",
       "Model                                                            \n",
       "ccxn                 0.2489  0.0296            0.8482  0.185   \n",
       "cwn                    0.2468  0.03            0.838  0.1286   \n",
       "cwn_dcm              0.2263  0.0187           0.8373  0.1206   \n",
       "\n",
       "Dataset US-county-demos-UnemploymentRate             ZINC      citeseer  \\\n",
       "Model                                                                     \n",
       "ccxn                     0.2707  0.0258  0.4187  0.0228  74.67  2.24   \n",
       "cwn                       0.2535  0.031   0.3497  0.012   75.2  1.82   \n",
       "cwn_dcm                        nan  nan  0.4089  0.0128  75.63  1.67   \n",
       "\n",
       "Dataset  minesweeper roman_empire  \n",
       "Model                              \n",
       "ccxn       nan  nan    nan  nan  \n",
       "cwn        nan  nan    nan  nan  \n",
       "cwn_dcm  89.42  0.0  82.14  0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_cell.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
