{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Simplicial\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{user}_{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{user}_{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_init.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate tables to obtain full hp space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiona_runs = pd.read_csv(f'gbg141_{project_name}.csv', index_col=0)\n",
    "df = pd.concat([df, additiona_runs], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models that have finished the runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/loss', 'val/precision', 'trainer/global_step', '_step', '_runtime']\n",
      "['val/auroc', 'train/accuracy', 'train/precision', 'epoch', 'val/recall']\n",
      "['train/auroc', 'train/recall', 'lr-Adam', '_timestamp', 'val/accuracy']\n",
      "['val/loss', 'seed', 'tags', 'extras', 'trainer']\n",
      "['ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable', 'model/params/non_trainable']\n",
      "['test/auroc', 'test/accuracy', '_wandb', 'test/recall', 'test/precision']\n",
      "['test/loss', 'train/mse', 'val/mae', 'val/mse', 'test/mae']\n",
      "['test/mse', 'train/mae', 'model.compile', 'model._target_', 'model.model_name']\n",
      "['model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type', 'model.readout._target_']\n",
      "['model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone._target_', 'model.backbone.n_layers']\n",
      "['model.backbone.in_channels_0', 'model.backbone.in_channels_1', 'model.backbone.in_channels_2', 'model.optimizer.lr', 'model.optimizer._target_']\n",
      "['model.optimizer._partial_', 'model.optimizer.weight_decay', 'model.scheduler._target_', 'model.scheduler._partial_', 'model.scheduler.last_epoch']\n",
      "['model.scheduler.total_iters', 'model.head_model._target_', 'model.head_model.task_level', 'model.head_model.in_channels', 'model.head_model.out_channels']\n",
      "['model.head_model.pooling_type', 'model.head_model.head_model_name', 'model.feature_encoder._target_', 'model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name']\n",
      "['model.feature_encoder.out_channels', 'model.feature_encoder.proj_dropout', 'model.feature_encoder.selected_dimensions', 'model.backbone_wrapper._target_', 'model.backbone_wrapper._partial_']\n",
      "['model.backbone_wrapper.out_channels', 'model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.channels', 'model.backbone.max_rank']\n",
      "['model.backbone.update_func', 'model.backbone.sc_order', 'model.backbone.aggr_norm', 'model.backbone.conv_order', 'model.backbone.in_channels_all']\n",
      "['model.backbone.hidden_channels_all', 'dataset._target_', 'dataset.parameters.k', 'dataset.parameters.task', 'dataset.parameters.data_dir']\n",
      "['dataset.parameters.data_name', 'dataset.parameters.data_seed', 'dataset.parameters.data_type', 'dataset.parameters.loss_type', 'dataset.parameters.batch_size']\n",
      "['dataset.parameters.pin_memory', 'dataset.parameters.split_type', 'dataset.parameters.task_level', 'dataset.parameters.train_prop', 'dataset.parameters.data_domain']\n",
      "['dataset.parameters.num_classes', 'dataset.parameters.num_workers', 'dataset.parameters.num_features', 'dataset.parameters.data_split_dir', 'dataset.parameters.monitor_metric']\n",
      "['dataset.transforms.graph2simplicial_lifting.signed', 'dataset.transforms.graph2simplicial_lifting._target_', 'dataset.transforms.graph2simplicial_lifting.complex_dim', 'dataset.transforms.graph2simplicial_lifting.transform_name', 'dataset.transforms.graph2simplicial_lifting.transform_type']\n",
      "['dataset.transforms.graph2simplicial_lifting.feature_lifting', 'dataset.transforms.graph2simplicial_lifting.preserve_edge_attr', 'dataset.parameters.force_reload', 'dataset.parameters.max_node_degree', 'dataset.transforms.data_manipulations._target_']\n",
      "['dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type', 'dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.one_hot_node_degree_features._target_', 'dataset.transforms.one_hot_node_degree_features.max_degree']\n",
      "['dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type', 'dataset.transforms.one_hot_node_degree_features.features_fields', 'dataset.parameters.year']\n",
      "['dataset.parameters.task_variable', 'dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted', 'callbacks.model_summary._target_', 'callbacks.model_summary.max_depth']\n",
      "['callbacks.early_stopping.mode', 'callbacks.early_stopping.strict', 'callbacks.early_stopping.monitor', 'callbacks.early_stopping.verbose', 'callbacks.early_stopping._target_']\n",
      "['callbacks.early_stopping.patience', 'callbacks.early_stopping.min_delta', 'callbacks.early_stopping.check_finite', 'callbacks.early_stopping.stopping_threshold', 'callbacks.early_stopping.divergence_threshold']\n",
      "['callbacks.early_stopping.check_on_train_epoch_end', 'callbacks.model_checkpoint.mode', 'callbacks.model_checkpoint.dirpath', 'callbacks.model_checkpoint.monitor', 'callbacks.model_checkpoint.verbose']\n",
      "['callbacks.model_checkpoint._target_', 'callbacks.model_checkpoint.filename', 'callbacks.model_checkpoint.save_last', 'callbacks.model_checkpoint.save_top_k', 'callbacks.model_checkpoint.every_n_epochs']\n",
      "['callbacks.model_checkpoint.save_weights_only', 'callbacks.model_checkpoint.every_n_train_steps', 'callbacks.model_checkpoint.train_time_interval', 'callbacks.model_checkpoint.auto_insert_metric_name', 'callbacks.model_checkpoint.save_on_train_epoch_end']\n",
      "['callbacks.rich_progress_bar._target_', 'callbacks.learning_rate_monitor._target_', 'callbacks.learning_rate_monitor.logging_interval', 'paths.log_dir', 'paths.data_dir']\n",
      "['paths.root_dir', 'paths.work_dir', 'paths.output_dir', 'epoch_run_time', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NCI1' 'NCI109' 'minesweeper' 'roman_empire' 'ZINC' 'PROTEINS' 'PubMed'\n",
      " 'citeseer' 'Cora' 'US-county-demos-UnemploymentRate'\n",
      " 'US-county-demos-BachelorRate' 'MUTAG' 'US-county-demos-DeathRate'\n",
      " 'US-county-demos-BirthRate' 'US-county-demos-MigraRate'\n",
      " 'US-county-demos-MedianIncome' 'US-county-demos-Election']\n",
      "Num unique datasets: 17\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scn' 'sccn' 'sccnn_custom']\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: sccnn_custom\n",
      "[1]\n",
      "[1]\n",
      "MODEL: scn\n",
      "[1]\n",
      "[1]\n",
      "MODEL: sccn\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['minesweeper', 'roman_empire']\n",
    "models = ['sccnn_custom', 'scn', 'sccn']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    print(\"MODEL:\", model)\n",
    "    for dataset in datasets:\n",
    "\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        \n",
    "        print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), 'dataset.parameters.batch_size'].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  0.25]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: scn\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[64 32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 3 4 1]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0 9 5 3 7]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[64 32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 3 4 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7 9 5 0 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32 128  64]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5 3 0 9 7]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: sccn\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32  64 128]\n",
      "Column: model.backbone.n_layers\n",
      "[1 4 3 2]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0 5 7 9 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 32  64 128]\n",
      "Column: model.backbone.n_layers\n",
      "[1 4 3 2]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 0 7 5 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5 7 0 3 9]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7 0 5 9 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 2]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128 256]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[  5   3 150  42  23]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7 3 0 9 5]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 0 5 3]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: sccnn_custom\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64  32 128]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0 3 7 9 5]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64  32 128]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 3 0 5]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 2]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0]\n",
      "Column: seed\n",
      "[ 23   5  42   3 150]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256 128]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64 32]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128  64  32]\n",
      "Column: model.backbone.n_layers\n",
      "[4 3 2 1]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[ True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9 7 5 3 0]\n",
      "Column: seed\n",
      "[42]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n"
     ]
    }
   ],
   "source": [
    "# Sweeped parameters: \n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'dataset.parameters.data_seed',\n",
    "    'seed',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "for model in df['model.model_name'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in df['dataset.parameters.data_name'].unique():\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for column in sweeped_columns:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "        print('---------------NEW DATASET------------------')\n",
    "    print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mae', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NCI1, Model: scn\n",
      "Initial number of rows, 473\n",
      "Final number of rows , 466\n",
      "Rows that had NANs number of rows , -7\n",
      "Dataset: NCI1, Model: sccn\n",
      "Initial number of rows, 689\n",
      "Final number of rows , 679\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI1, Model: sccnn_custom\n",
      "Initial number of rows, 647\n",
      "Final number of rows , 646\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: NCI109, Model: scn\n",
      "Initial number of rows, 490\n",
      "Final number of rows , 485\n",
      "Rows that had NANs number of rows , -5\n",
      "Dataset: NCI109, Model: sccn\n",
      "Initial number of rows, 679\n",
      "Final number of rows , 669\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI109, Model: sccnn_custom\n",
      "Initial number of rows, 639\n",
      "Final number of rows , 638\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: scn\n",
      "Initial number of rows, 636\n",
      "Final number of rows , 635\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 478\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccn\n",
      "Initial number of rows, 469\n",
      "Final number of rows , 469\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: scn\n",
      "Initial number of rows, 0\n",
      "Final number of rows , 0\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: sccn\n",
      "Initial number of rows, 451\n",
      "Final number of rows , 439\n",
      "Rows that had NANs number of rows , -12\n",
      "Dataset: ZINC, Model: sccnn_custom\n",
      "Initial number of rows, 465\n",
      "Final number of rows , 465\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: scn\n",
      "Initial number of rows, 961\n",
      "Final number of rows , 961\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: citeseer, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: Cora, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 461\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 459\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 959\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: MUTAG, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: scn\n",
      "Initial number of rows, 448\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-DeathRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: scn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BirthRate, Model: sccn\n",
      "Initial number of rows, 456\n",
      "Final number of rows , 456\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: scn\n",
      "Initial number of rows, 460\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 450\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 462\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccn\n",
      "Initial number of rows, 434\n",
      "Final number of rows , 434\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccn\n",
      "Initial number of rows, 454\n",
      "Final number of rows , 454\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        init_num_of_rows = subset.shape[0]\n",
    "        print(f'Initial number of rows, {init_num_of_rows}')\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan        \n",
    "    \n",
    "        if total_performance_nan > 0:\n",
    "          \n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "           \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "    \n",
    "        for column in performance_columns:\n",
    "            if subset[column].isna().sum() > 0:  \n",
    "                subset = subset[~subset[column].isna()]\n",
    "\n",
    "        final_num_of_rows = subset.shape[0]  \n",
    "        print(f'Final number of rows , {final_num_of_rows}')\n",
    "        print(f'Rows that had NANs number of rows , {final_num_of_rows - init_num_of_rows}')\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        if final_best[(eval_metric, \"mean\")].any(): \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "            }\n",
    "\n",
    "            # Extract best runs: \n",
    "            best_params = {}\n",
    "            for col in sweeped_columns:\n",
    "                best_params[col] = final_best[(col, '')].item()\n",
    "            \n",
    "            hp_runs[dataset][model] = subset.copy()\n",
    "            \n",
    "            # Start with the entire DataFrame\n",
    "            filtered_subset = subset.copy()\n",
    "\n",
    "            # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "            for param, value in best_params.items():\n",
    "                filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "            best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "        else: \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": np.nan,\n",
    "                \"std\": np.nan,\n",
    "            }\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "COLS = [\n",
    "    'dataset.parameters.data_seed',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'model.optimizer.lr', \n",
    "    \n",
    "]\n",
    "\n",
    "a = hp_runs['US-county-demos-BirthRate']['scn'].sort_values(by=COLS, ascending=False)[COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in COLS:\n",
    "#     print(a[col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sccn</th>\n",
       "      <td>80.86  2.16</td>\n",
       "      <td>70.64  5.9</td>\n",
       "      <td>76.17  1.39</td>\n",
       "      <td>75.49  1.39</td>\n",
       "      <td>75.05  2.76</td>\n",
       "      <td>88.37  0.48</td>\n",
       "      <td>0.3588  0.0246</td>\n",
       "      <td>0.8242  0.0942</td>\n",
       "      <td>0.5751  0.0553</td>\n",
       "      <td>0.5344  0.0323</td>\n",
       "      <td>0.2908  0.032</td>\n",
       "      <td>0.9146  0.1822</td>\n",
       "      <td>0.4328  0.044</td>\n",
       "      <td>0.4858  0.0584</td>\n",
       "      <td>69.6  1.83</td>\n",
       "      <td>89.07  0.25</td>\n",
       "      <td>88.27  0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sccnn_custom</th>\n",
       "      <td>82.19  1.07</td>\n",
       "      <td>76.17  6.63</td>\n",
       "      <td>76.6  1.75</td>\n",
       "      <td>77.12  1.07</td>\n",
       "      <td>74.19  2.86</td>\n",
       "      <td>88.18  0.32</td>\n",
       "      <td>0.3394  0.028</td>\n",
       "      <td>0.7937  0.1162</td>\n",
       "      <td>0.5527  0.0474</td>\n",
       "      <td>0.5112  0.0316</td>\n",
       "      <td>0.2825  0.0279</td>\n",
       "      <td>0.8976  0.1431</td>\n",
       "      <td>0.4278  0.0394</td>\n",
       "      <td>0.4088  0.0047</td>\n",
       "      <td>70.23  2.69</td>\n",
       "      <td>89.0  0.0</td>\n",
       "      <td>89.15  0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn</th>\n",
       "      <td>82.27  1.34</td>\n",
       "      <td>73.62  6.13</td>\n",
       "      <td>74.46  1.11</td>\n",
       "      <td>75.7  1.04</td>\n",
       "      <td>75.27  2.14</td>\n",
       "      <td>88.72  0.5</td>\n",
       "      <td>0.3186  0.0241</td>\n",
       "      <td>0.7122  0.0836</td>\n",
       "      <td>0.5208  0.0525</td>\n",
       "      <td>0.4648  0.043</td>\n",
       "      <td>0.2526  0.0247</td>\n",
       "      <td>0.9209  0.1993</td>\n",
       "      <td>0.3753  0.0432</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>71.24  1.68</td>\n",
       "      <td>90.32  0.11</td>\n",
       "      <td>88.79  0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset               Cora         MUTAG          NCI1        NCI109      PROTEINS        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "Model                                                                                                                                                                                                                                                                                                                                                        \n",
       "sccn          80.86  2.16   70.64  5.9  76.17  1.39  75.49  1.39  75.05  2.76  88.37  0.48              0.3588  0.0246           0.8242  0.0942           0.5751  0.0553          0.5344  0.0323               0.2908  0.032           0.9146  0.1822                   0.4328  0.044  0.4858  0.0584   69.6  1.83  89.07  0.25  88.27  0.14\n",
       "sccnn_custom  82.19  1.07  76.17  6.63   76.6  1.75  77.12  1.07  74.19  2.86  88.18  0.32               0.3394  0.028           0.7937  0.1162           0.5527  0.0474          0.5112  0.0316              0.2825  0.0279           0.8976  0.1431                  0.4278  0.0394  0.4088  0.0047  70.23  2.69    89.0  0.0  89.15  0.32\n",
       "scn           82.27  1.34  73.62  6.13  74.46  1.11   75.7  1.04  75.27  2.14   88.72  0.5              0.3186  0.0241           0.7122  0.0836           0.5208  0.0525           0.4648  0.043              0.2526  0.0247           0.9209  0.1993                  0.3753  0.0432        nan  nan  71.24  1.68  90.32  0.11  88.79  0.46"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate signal down comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NCI1, Model: scn\n",
      "Initial number of rows, 473\n",
      "Final number of rows , 466\n",
      "Rows that had NANs number of rows , -7\n",
      "Dataset: NCI1, Model: sccn\n",
      "Initial number of rows, 689\n",
      "Final number of rows , 679\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI1, Model: sccnn_custom\n",
      "Initial number of rows, 647\n",
      "Final number of rows , 646\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: NCI109, Model: scn\n",
      "Initial number of rows, 490\n",
      "Final number of rows , 485\n",
      "Rows that had NANs number of rows , -5\n",
      "Dataset: NCI109, Model: sccn\n",
      "Initial number of rows, 679\n",
      "Final number of rows , 669\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI109, Model: sccnn_custom\n",
      "Initial number of rows, 639\n",
      "Final number of rows , 638\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: scn\n",
      "Initial number of rows, 636\n",
      "Final number of rows , 635\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 478\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccn\n",
      "Initial number of rows, 469\n",
      "Final number of rows , 469\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: scn\n",
      "Initial number of rows, 0\n",
      "Final number of rows , 0\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: sccn\n",
      "Initial number of rows, 451\n",
      "Final number of rows , 439\n",
      "Rows that had NANs number of rows , -12\n",
      "Dataset: ZINC, Model: sccnn_custom\n",
      "Initial number of rows, 465\n",
      "Final number of rows , 465\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: scn\n",
      "Initial number of rows, 961\n",
      "Final number of rows , 961\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: citeseer, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: Cora, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 461\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 459\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 959\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: MUTAG, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: scn\n",
      "Initial number of rows, 448\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-DeathRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: scn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BirthRate, Model: sccn\n",
      "Initial number of rows, 456\n",
      "Final number of rows , 456\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: scn\n",
      "Initial number of rows, 460\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 450\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 462\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccn\n",
      "Initial number of rows, 434\n",
      "Final number of rows , 434\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccn\n",
      "Initial number of rows, 454\n",
      "Final number of rows , 454\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        init_num_of_rows = subset.shape[0]\n",
    "        print(f'Initial number of rows, {init_num_of_rows}')\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan        \n",
    "    \n",
    "        if total_performance_nan > 0:\n",
    "          \n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "           \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "    \n",
    "        for column in performance_columns:\n",
    "            if subset[column].isna().sum() > 0:  \n",
    "                subset = subset[~subset[column].isna()]\n",
    "\n",
    "        final_num_of_rows = subset.shape[0]  \n",
    "        print(f'Final number of rows , {final_num_of_rows}')\n",
    "        print(f'Rows that had NANs number of rows , {final_num_of_rows - init_num_of_rows}')\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "        if sorted(list(aggregated['model.readout.readout_name'].unique())) == sorted(['NoReadOut', 'PropagateSignalDown']):\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                agg_sub = aggregated[aggregated['model.readout.readout_name'] == prop_type]\n",
    "                agg_sub = agg_sub.sort_values(\n",
    "                    by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "                )\n",
    "                \n",
    "                final_best = agg_sub.head(1)\n",
    "                if final_best[(eval_metric, \"mean\")].any(): \n",
    "                    best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                        \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                        \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "                    }\n",
    "\n",
    "                    # Extract best runs: \n",
    "                    best_params = {}\n",
    "                    for col in sweeped_columns:\n",
    "                        best_params[col] = final_best[(col, '')].item()\n",
    "                    \n",
    "                    hp_runs[dataset][model] = subset.copy()\n",
    "                    \n",
    "                    # Start with the entire DataFrame\n",
    "                    filtered_subset = subset.copy()\n",
    "\n",
    "                    # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "                    for param, value in best_params.items():\n",
    "                        filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "                    best_runs[dataset][model] = filtered_subset\n",
    "                \n",
    "                else: \n",
    "                    best_results[dataset][model] = {\n",
    "                        \"mean\": np.nan,\n",
    "                        \"std\": np.nan,\n",
    "                        \"prop_type\": prop_type\n",
    "                    }\n",
    "        else:\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                            \"mean\": np.nan,\n",
    "                            \"std\": np.nan,\n",
    "                        }\n",
    "\n",
    "       \n",
    "\n",
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")\n",
    "result_dict.reset_index(inplace=True)\n",
    "\n",
    "result_dict['ReadOut'] = result_dict['Model'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "result_dict['Model'] = result_dict['Model'].apply(lambda x: x.split('(')[0])\n",
    "\n",
    "result_dict.sort_values(by=['Model','ReadOut'], inplace=True)\n",
    "\n",
    "columns = ['Model',\n",
    "'ReadOut',\n",
    " 'Cora',\n",
    " 'MUTAG',\n",
    " 'NCI1',\n",
    " 'NCI109',\n",
    " 'PROTEINS',\n",
    " 'PubMed',\n",
    " 'US-county-demos-BachelorRate',\n",
    " 'US-county-demos-BirthRate',\n",
    " 'US-county-demos-DeathRate',\n",
    " 'US-county-demos-Election',\n",
    " 'US-county-demos-MedianIncome',\n",
    " 'US-county-demos-MigraRate',\n",
    " 'US-county-demos-UnemploymentRate',\n",
    " 'ZINC',\n",
    " 'citeseer',\n",
    " 'minesweeper',\n",
    " 'roman_empire',]\n",
    "result_dict = result_dict[columns]\n",
    "result_dict.to_csv(f\"ablation_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>ReadOut</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sccn</td>\n",
       "      <td>NoReadOut</td>\n",
       "      <td>80.86  2.16</td>\n",
       "      <td>70.64  5.9</td>\n",
       "      <td>76.42  0.88</td>\n",
       "      <td>75.49  1.39</td>\n",
       "      <td>75.05  2.76</td>\n",
       "      <td>88.04  0.51</td>\n",
       "      <td>0.3588  0.0246</td>\n",
       "      <td>0.8242  0.0942</td>\n",
       "      <td>0.5751  0.0553</td>\n",
       "      <td>0.5344  0.0323</td>\n",
       "      <td>0.2868  0.0276</td>\n",
       "      <td>0.9146  0.1822</td>\n",
       "      <td>0.4328  0.044</td>\n",
       "      <td>0.5441  0.0081</td>\n",
       "      <td>69.6  1.83</td>\n",
       "      <td>88.85  0.0</td>\n",
       "      <td>88.2  0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sccn</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>80.06  1.66</td>\n",
       "      <td>73.62  4.41</td>\n",
       "      <td>76.17  1.39</td>\n",
       "      <td>75.31  1.36</td>\n",
       "      <td>74.34  3.17</td>\n",
       "      <td>88.37  0.48</td>\n",
       "      <td>0.341  0.0249</td>\n",
       "      <td>0.8264  0.1018</td>\n",
       "      <td>0.5629  0.0444</td>\n",
       "      <td>0.5686  0.0247</td>\n",
       "      <td>0.2908  0.032</td>\n",
       "      <td>0.9303  0.172</td>\n",
       "      <td>0.4734  0.0377</td>\n",
       "      <td>0.4858  0.0584</td>\n",
       "      <td>68.86  2.4</td>\n",
       "      <td>89.07  0.25</td>\n",
       "      <td>88.27  0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>NoReadOut</td>\n",
       "      <td>82.19  1.07</td>\n",
       "      <td>76.17  6.63</td>\n",
       "      <td>76.6  1.75</td>\n",
       "      <td>77.12  1.07</td>\n",
       "      <td>74.19  2.86</td>\n",
       "      <td>88.18  0.32</td>\n",
       "      <td>0.3394  0.028</td>\n",
       "      <td>0.7937  0.1162</td>\n",
       "      <td>0.5527  0.0474</td>\n",
       "      <td>0.5112  0.0316</td>\n",
       "      <td>0.2825  0.0279</td>\n",
       "      <td>0.8976  0.1431</td>\n",
       "      <td>0.4278  0.0394</td>\n",
       "      <td>0.3562  0.013</td>\n",
       "      <td>70.23  2.69</td>\n",
       "      <td>87.4  0.0</td>\n",
       "      <td>89.15  0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>80.65  2.39</td>\n",
       "      <td>70.64  3.16</td>\n",
       "      <td>75.6  2.45</td>\n",
       "      <td>75.43  1.94</td>\n",
       "      <td>74.98  1.92</td>\n",
       "      <td>87.78  0.58</td>\n",
       "      <td>0.3449  0.0314</td>\n",
       "      <td>0.8251  0.1184</td>\n",
       "      <td>0.579  0.0541</td>\n",
       "      <td>0.557  0.041</td>\n",
       "      <td>0.3073  0.0316</td>\n",
       "      <td>0.9274  0.1711</td>\n",
       "      <td>0.4538  0.0428</td>\n",
       "      <td>0.4088  0.0047</td>\n",
       "      <td>69.03  2.01</td>\n",
       "      <td>89.0  0.0</td>\n",
       "      <td>88.73  0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scn</td>\n",
       "      <td>NoReadOut</td>\n",
       "      <td>82.27  1.34</td>\n",
       "      <td>71.49  2.43</td>\n",
       "      <td>75.27  1.57</td>\n",
       "      <td>75.7  nan</td>\n",
       "      <td>75.27  2.14</td>\n",
       "      <td>88.72  0.5</td>\n",
       "      <td>0.3186  0.0241</td>\n",
       "      <td>0.7122  0.0836</td>\n",
       "      <td>0.5208  0.0525</td>\n",
       "      <td>0.4648  0.043</td>\n",
       "      <td>0.2526  0.0247</td>\n",
       "      <td>0.9209  0.1993</td>\n",
       "      <td>0.3753  0.0432</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>71.24  1.68</td>\n",
       "      <td>90.32  0.11</td>\n",
       "      <td>85.89  0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scn</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>79.91  1.18</td>\n",
       "      <td>73.62  6.13</td>\n",
       "      <td>74.46  1.11</td>\n",
       "      <td>75.7  1.04</td>\n",
       "      <td>74.77  1.69</td>\n",
       "      <td>88.62  0.44</td>\n",
       "      <td>0.3205  0.0271</td>\n",
       "      <td>0.7985  0.1062</td>\n",
       "      <td>0.5635  0.0457</td>\n",
       "      <td>0.5091  0.0345</td>\n",
       "      <td>0.2723  0.0174</td>\n",
       "      <td>0.9619  0.2329</td>\n",
       "      <td>0.4131  0.0297</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>70.4  1.53</td>\n",
       "      <td>90.27  0.36</td>\n",
       "      <td>88.79  0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Model              ReadOut          Cora         MUTAG          NCI1        NCI109      PROTEINS        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "0                sccn             NoReadOut  80.86  2.16   70.64  5.9  76.42  0.88  75.49  1.39  75.05  2.76  88.04  0.51              0.3588  0.0246           0.8242  0.0942           0.5751  0.0553          0.5344  0.0323              0.2868  0.0276           0.9146  0.1822                   0.4328  0.044  0.5441  0.0081   69.6  1.83   88.85  0.0   88.2  0.22\n",
       "1                sccn   PropagateSignalDown  80.06  1.66  73.62  4.41  76.17  1.39  75.31  1.36  74.34  3.17  88.37  0.48               0.341  0.0249           0.8264  0.1018           0.5629  0.0444          0.5686  0.0247               0.2908  0.032            0.9303  0.172                  0.4734  0.0377  0.4858  0.0584   68.86  2.4  89.07  0.25  88.27  0.14\n",
       "2        sccnn_custom             NoReadOut  82.19  1.07  76.17  6.63   76.6  1.75  77.12  1.07  74.19  2.86  88.18  0.32               0.3394  0.028           0.7937  0.1162           0.5527  0.0474          0.5112  0.0316              0.2825  0.0279           0.8976  0.1431                  0.4278  0.0394   0.3562  0.013  70.23  2.69    87.4  0.0  89.15  0.32\n",
       "3        sccnn_custom   PropagateSignalDown  80.65  2.39  70.64  3.16   75.6  2.45  75.43  1.94  74.98  1.92  87.78  0.58              0.3449  0.0314           0.8251  0.1184            0.579  0.0541            0.557  0.041              0.3073  0.0316           0.9274  0.1711                  0.4538  0.0428  0.4088  0.0047  69.03  2.01    89.0  0.0  88.73  0.12\n",
       "4                 scn             NoReadOut  82.27  1.34  71.49  2.43  75.27  1.57    75.7  nan  75.27  2.14   88.72  0.5              0.3186  0.0241           0.7122  0.0836           0.5208  0.0525           0.4648  0.043              0.2526  0.0247           0.9209  0.1993                  0.3753  0.0432        nan  nan  71.24  1.68  90.32  0.11  85.89  0.34\n",
       "5                 scn   PropagateSignalDown  79.91  1.18  73.62  6.13  74.46  1.11   75.7  1.04  74.77  1.69  88.62  0.44              0.3205  0.0271           0.7985  0.1062           0.5635  0.0457          0.5091  0.0345              0.2723  0.0174           0.9619  0.2329                  0.4131  0.0297        nan  nan   70.4  1.53  90.27  0.36  88.79  0.46"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
