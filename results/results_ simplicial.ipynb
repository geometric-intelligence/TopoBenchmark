{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Simplicial\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{user}_{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{user}_{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_init.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate tables to obtain full hp space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiona_runs = pd.read_csv(f'gbg141_{project_name}.csv', index_col=0)\n",
    "df = pd.concat([df, additiona_runs], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models that have finished the runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/precision', 'train/loss', 'val/recall', 'val/accuracy', '_timestamp']\n",
      "['train/auroc', 'train/accuracy', 'val/precision', 'trainer/global_step', '_step']\n",
      "['epoch', 'val/loss', 'train/recall', 'lr-Adam', '_runtime']\n",
      "['val/auroc', 'seed', 'tags', 'extras', 'trainer']\n",
      "['ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable', 'model/params/non_trainable']\n",
      "['test/loss', 'test/recall', '_wandb', 'test/auroc', 'test/accuracy']\n",
      "['test/precision', 'train/mae', 'train/mse', 'val/mae', 'val/mse']\n",
      "['test/mae', 'test/mse', 'model.compile', 'model._target_', 'model.model_name']\n",
      "['model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type', 'model.readout._target_']\n",
      "['model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone._target_', 'model.backbone.channels']\n",
      "['model.backbone.max_rank', 'model.backbone.n_layers', 'model.backbone.update_func', 'model.optimizer.lr', 'model.optimizer._target_']\n",
      "['model.optimizer._partial_', 'model.optimizer.weight_decay', 'model.scheduler._target_', 'model.scheduler._partial_', 'model.scheduler.last_epoch']\n",
      "['model.scheduler.total_iters', 'model.head_model._target_', 'model.head_model.task_level', 'model.head_model.in_channels', 'model.head_model.out_channels']\n",
      "['model.head_model.pooling_type', 'model.head_model.head_model_name', 'model.feature_encoder._target_', 'model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name']\n",
      "['model.feature_encoder.out_channels', 'model.feature_encoder.proj_dropout', 'model.backbone_wrapper._target_', 'model.backbone_wrapper._partial_', 'model.backbone_wrapper.out_channels']\n",
      "['model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.in_channels_0', 'model.backbone.in_channels_1', 'model.backbone.in_channels_2']\n",
      "['model.feature_encoder.selected_dimensions', 'model.backbone.sc_order', 'model.backbone.aggr_norm', 'model.backbone.conv_order', 'model.backbone.in_channels_all']\n",
      "['model.backbone.hidden_channels_all', 'dataset._target_', 'dataset.parameters.k', 'dataset.parameters.task', 'dataset.parameters.data_dir']\n",
      "['dataset.parameters.data_name', 'dataset.parameters.data_seed', 'dataset.parameters.data_type', 'dataset.parameters.loss_type', 'dataset.parameters.batch_size']\n",
      "['dataset.parameters.pin_memory', 'dataset.parameters.split_type', 'dataset.parameters.task_level', 'dataset.parameters.train_prop', 'dataset.parameters.data_domain']\n",
      "['dataset.parameters.num_classes', 'dataset.parameters.num_workers', 'dataset.parameters.num_features', 'dataset.parameters.data_split_dir', 'dataset.parameters.max_x_1_degree']\n",
      "['dataset.parameters.monitor_metric', 'dataset.parameters.max_node_degree', 'dataset.transforms.data_manipulations._target_', 'dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type']\n",
      "['dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.graph2simplicial_lifting.signed', 'dataset.transforms.graph2simplicial_lifting._target_', 'dataset.transforms.graph2simplicial_lifting.complex_dim', 'dataset.transforms.graph2simplicial_lifting.transform_name']\n",
      "['dataset.transforms.graph2simplicial_lifting.transform_type', 'dataset.transforms.graph2simplicial_lifting.feature_lifting', 'dataset.transforms.graph2simplicial_lifting.preserve_edge_attr', 'dataset.transforms.one_hot_node_degree_features._target_', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n",
      "['dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type', 'dataset.transforms.one_hot_node_degree_features.features_fields', 'dataset.parameters.force_reload']\n",
      "['dataset.transforms.one_hot_node_degree_features.max_degree', 'dataset.parameters.year', 'dataset.parameters.task_variable', 'dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted']\n",
      "['callbacks.model_summary._target_', 'callbacks.model_summary.max_depth', 'callbacks.early_stopping.mode', 'callbacks.early_stopping.strict', 'callbacks.early_stopping.monitor']\n",
      "['callbacks.early_stopping.verbose', 'callbacks.early_stopping._target_', 'callbacks.early_stopping.patience', 'callbacks.early_stopping.min_delta', 'callbacks.early_stopping.check_finite']\n",
      "['callbacks.early_stopping.stopping_threshold', 'callbacks.early_stopping.divergence_threshold', 'callbacks.early_stopping.check_on_train_epoch_end', 'callbacks.model_checkpoint.mode', 'callbacks.model_checkpoint.dirpath']\n",
      "['callbacks.model_checkpoint.monitor', 'callbacks.model_checkpoint.verbose', 'callbacks.model_checkpoint._target_', 'callbacks.model_checkpoint.filename', 'callbacks.model_checkpoint.save_last']\n",
      "['callbacks.model_checkpoint.save_top_k', 'callbacks.model_checkpoint.every_n_epochs', 'callbacks.model_checkpoint.save_weights_only', 'callbacks.model_checkpoint.every_n_train_steps', 'callbacks.model_checkpoint.train_time_interval']\n",
      "['callbacks.model_checkpoint.auto_insert_metric_name', 'callbacks.model_checkpoint.save_on_train_epoch_end', 'callbacks.rich_progress_bar._target_', 'callbacks.learning_rate_monitor._target_', 'callbacks.learning_rate_monitor.logging_interval']\n",
      "['paths.log_dir', 'paths.data_dir', 'paths.root_dir', 'paths.work_dir', 'paths.output_dir']\n",
      "['epoch_run_time', 'dataset.transforms.data_manipulations.std', 'dataset.transforms.data_manipulations.mean', 'dataset.transforms.data_manipulations.num_features']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMDB-BINARY' 'IMDB-MULTI' nan 'ZINC' 'minesweeper' 'NCI1' 'NCI109'\n",
      " 'roman_empire' 'PROTEINS' 'PubMed' 'citeseer' 'Cora'\n",
      " 'US-county-demos-UnemploymentRate' 'US-county-demos-BachelorRate' 'MUTAG'\n",
      " 'US-county-demos-DeathRate' 'US-county-demos-BirthRate'\n",
      " 'US-county-demos-MigraRate' 'US-county-demos-MedianIncome'\n",
      " 'US-county-demos-Election' 'REDDIT-BINARY']\n",
      "Num unique datasets: 21\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sccn' 'scn' 'sccnn_custom' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: sccnn_custom\n",
      "[1.]\n",
      "[1.]\n",
      "MODEL: scn\n",
      "[1.]\n",
      "[1.]\n",
      "MODEL: sccn\n",
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['minesweeper', 'roman_empire']\n",
    "models = ['sccnn_custom', 'scn', 'sccn']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    print(\"MODEL:\", model)\n",
    "    for dataset in datasets:\n",
    "\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        \n",
    "        print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), 'dataset.parameters.batch_size'].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.5   nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweeped parameters: \n",
    "# sweeped_columns = [\n",
    "#     'model.optimizer.lr', \n",
    "#     'model.feature_encoder.out_channels',\n",
    "#     'model.backbone.n_layers',\n",
    "#     'model.readout.readout_name',\n",
    "#     'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "#     'model.feature_encoder.proj_dropout',\n",
    "#     'dataset.parameters.batch_size',\n",
    "#     'dataset.parameters.data_seed',\n",
    "#     'seed',\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "# for model in df['model.model_name'].unique():\n",
    "#     print(f\"Model: {model}\")\n",
    "#     for dataset in df['dataset.parameters.data_name'].unique():\n",
    "#         print(f\"Dataset: {dataset}\")\n",
    "#         for column in sweeped_columns:\n",
    "#             print(f\"Column: {column}\")\n",
    "#             print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "#         print('---------------NEW DATASET------------------')\n",
    "#     print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'model/params/total',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mae', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: IMDB-BINARY, Model: sccn\n",
      "Initial number of rows, 436\n",
      "Final number of rows , 435\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: IMDB-BINARY, Model: scn\n",
      "Initial number of rows, 142\n",
      "Final number of rows , 141\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: IMDB-BINARY, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: IMDB-MULTI, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: IMDB-MULTI, Model: scn\n",
      "Initial number of rows, 134\n",
      "Final number of rows , 132\n",
      "Rows that had NANs number of rows , -2\n",
      "Dataset: IMDB-MULTI, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: sccn\n",
      "Initial number of rows, 451\n",
      "Final number of rows , 439\n",
      "Rows that had NANs number of rows , -12\n",
      "Dataset: ZINC, Model: scn\n",
      "Initial number of rows, 370\n",
      "Final number of rows , 351\n",
      "Rows that had NANs number of rows , -19\n",
      "Dataset: ZINC, Model: sccnn_custom\n",
      "Initial number of rows, 465\n",
      "Final number of rows , 465\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: minesweeper, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 478\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: scn\n",
      "Initial number of rows, 720\n",
      "Final number of rows , 720\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: minesweeper, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: NCI1, Model: sccn\n",
      "Initial number of rows, 689\n",
      "Final number of rows , 679\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI1, Model: scn\n",
      "Initial number of rows, 533\n",
      "Final number of rows , 531\n",
      "Rows that had NANs number of rows , -2\n",
      "Dataset: NCI1, Model: sccnn_custom\n",
      "Initial number of rows, 647\n",
      "Final number of rows , 646\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: NCI109, Model: sccn\n",
      "Initial number of rows, 679\n",
      "Final number of rows , 669\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI109, Model: scn\n",
      "Initial number of rows, 537\n",
      "Final number of rows , 537\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: NCI109, Model: sccnn_custom\n",
      "Initial number of rows, 639\n",
      "Final number of rows , 638\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: roman_empire, Model: sccn\n",
      "Initial number of rows, 469\n",
      "Final number of rows , 469\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: citeseer, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: Cora, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: scn\n",
      "Initial number of rows, 461\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 459\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 959\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: MUTAG, Model: scn\n",
      "Initial number of rows, 961\n",
      "Final number of rows , 961\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: scn\n",
      "Initial number of rows, 448\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-DeathRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: sccn\n",
      "Initial number of rows, 456\n",
      "Final number of rows , 456\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: scn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BirthRate, Model: sccnn_custom\n",
      "Initial number of rows, 481\n",
      "Final number of rows , 481\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 450\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: scn\n",
      "Initial number of rows, 460\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccn\n",
      "Initial number of rows, 434\n",
      "Final number of rows , 434\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 462\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccn\n",
      "Initial number of rows, 454\n",
      "Final number of rows , 454\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: REDDIT-BINARY, Model: sccn\n",
      "Initial number of rows, 20\n",
      "Final number of rows , 19\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: REDDIT-BINARY, Model: scn\n",
      "Initial number of rows, 26\n",
      "Final number of rows , 25\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: REDDIT-BINARY, Model: sccnn_custom\n",
      "Initial number of rows, 22\n",
      "Final number of rows , 21\n",
      "Rows that had NANs number of rows , -1\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "collect_bast_parameters = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        init_num_of_rows = subset.shape[0]\n",
    "        print(f'Initial number of rows, {init_num_of_rows}')\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan        \n",
    "    \n",
    "        if total_performance_nan > 0:\n",
    "          \n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "           \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "    \n",
    "        for column in performance_columns:\n",
    "            if subset[column].isna().sum() > 0:  \n",
    "                subset = subset[~subset[column].isna()]\n",
    "\n",
    "        final_num_of_rows = subset.shape[0]  \n",
    "        print(f'Final number of rows , {final_num_of_rows}')\n",
    "        print(f'Rows that had NANs number of rows , {final_num_of_rows - init_num_of_rows}')\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        if final_best[(eval_metric, \"mean\")].any(): \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "            }\n",
    "\n",
    "            # Extract best runs: \n",
    "            best_params = {}\n",
    "            for col in sweeped_columns:\n",
    "                best_params[col] = final_best[(col, '')].item()\n",
    "            \n",
    "            collect_bast_parameters[dataset][model] = best_params\n",
    "            \n",
    "            hp_runs[dataset][model] = subset.copy()\n",
    "            \n",
    "            # Start with the entire DataFrame\n",
    "            filtered_subset = subset.copy()\n",
    "\n",
    "            # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "            for param, value in best_params.items():\n",
    "                filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "            best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "        else: \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": np.nan,\n",
    "                \"std\": np.nan,\n",
    "            }\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "COLS = [\n",
    "    'dataset.parameters.data_seed',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'model.optimizer.lr', \n",
    "    \n",
    "]\n",
    "\n",
    "a = hp_runs['US-county-demos-BirthRate']['scn'].sort_values(by=COLS, ascending=False)[COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in COLS:\n",
    "#     print(a[col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>dataset.parameters.data_name</th>\n",
       "      <th>model.optimizer.lr</th>\n",
       "      <th>model.feature_encoder.out_channels</th>\n",
       "      <th>model.backbone.n_layers</th>\n",
       "      <th>model.readout.readout_name</th>\n",
       "      <th>dataset.transforms.graph2simplicial_lifting.signed</th>\n",
       "      <th>model.feature_encoder.proj_dropout</th>\n",
       "      <th>dataset.parameters.batch_size</th>\n",
       "      <th>model/params/total</th>\n",
       "      <th>val/accuracy</th>\n",
       "      <th>test/accuracy</th>\n",
       "      <th>val/auroc</th>\n",
       "      <th>test/auroc</th>\n",
       "      <th>val/recall</th>\n",
       "      <th>test/recall</th>\n",
       "      <th>val/precision</th>\n",
       "      <th>test/precision</th>\n",
       "      <th>dataset.parameters.data_seed</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5891</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>minesweeper</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33442.0</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.881485</td>\n",
       "      <td>0.890040</td>\n",
       "      <td>0.706481</td>\n",
       "      <td>0.720590</td>\n",
       "      <td>0.746548</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>minesweeper</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33442.0</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.881501</td>\n",
       "      <td>0.890032</td>\n",
       "      <td>0.706732</td>\n",
       "      <td>0.720839</td>\n",
       "      <td>0.747347</td>\n",
       "      <td>0.749202</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>minesweeper</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33442.0</td>\n",
       "      <td>0.8368</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.881415</td>\n",
       "      <td>0.890005</td>\n",
       "      <td>0.706982</td>\n",
       "      <td>0.719835</td>\n",
       "      <td>0.748151</td>\n",
       "      <td>0.748533</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>minesweeper</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33442.0</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.881483</td>\n",
       "      <td>0.890021</td>\n",
       "      <td>0.706732</td>\n",
       "      <td>0.719586</td>\n",
       "      <td>0.747347</td>\n",
       "      <td>0.747787</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>minesweeper</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33442.0</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.881475</td>\n",
       "      <td>0.890033</td>\n",
       "      <td>0.706481</td>\n",
       "      <td>0.720590</td>\n",
       "      <td>0.746548</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model.model_name dataset.parameters.data_name  model.optimizer.lr  model.feature_encoder.out_channels  model.backbone.n_layers model.readout.readout_name dataset.transforms.graph2simplicial_lifting.signed  model.feature_encoder.proj_dropout  dataset.parameters.batch_size  model/params/total  val/accuracy  test/accuracy  val/auroc  test/auroc  val/recall  test/recall  val/precision  test/precision  dataset.parameters.data_seed  seed\n",
       "5891     sccnn_custom                  minesweeper               0.001                                32.0                      1.0        PropagateSignalDown                                               True                                 0.5                            1.0             33442.0        0.8360         0.8388   0.881485    0.890040    0.706481     0.720590       0.746548        0.748457                           9.0  42.0\n",
       "5895     sccnn_custom                  minesweeper               0.001                                32.0                      1.0        PropagateSignalDown                                               True                                 0.5                            1.0             33442.0        0.8364         0.8392   0.881501    0.890032    0.706732     0.720839       0.747347        0.749202                           7.0  42.0\n",
       "5900     sccnn_custom                  minesweeper               0.001                                32.0                      1.0        PropagateSignalDown                                               True                                 0.5                            1.0             33442.0        0.8368         0.8388   0.881415    0.890005    0.706982     0.719835       0.748151        0.748533                           5.0  42.0\n",
       "5903     sccnn_custom                  minesweeper               0.001                                32.0                      1.0        PropagateSignalDown                                               True                                 0.5                            1.0             33442.0        0.8364         0.8384   0.881483    0.890021    0.706732     0.719586       0.747347        0.747787                           3.0  42.0\n",
       "5906     sccnn_custom                  minesweeper               0.001                                32.0                      1.0        PropagateSignalDown                                               True                                 0.5                            1.0             33442.0        0.8360         0.8388   0.881475    0.890033    0.706481     0.720590       0.746548        0.748457                           0.0  42.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_runs['minesweeper']['sccnn_custom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']} Â± {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>IMDB-BINARY</th>\n",
       "      <th>IMDB-MULTI</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>REDDIT-BINARY</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sccn</th>\n",
       "      <td>80.86 Â± 2.16</td>\n",
       "      <td>70.88 Â± 3.98</td>\n",
       "      <td>49.33 Â± 1.87</td>\n",
       "      <td>70.64 Â± 5.9</td>\n",
       "      <td>76.17 Â± 1.39</td>\n",
       "      <td>75.49 Â± 1.39</td>\n",
       "      <td>75.05 Â± 2.76</td>\n",
       "      <td>88.37 Â± 0.48</td>\n",
       "      <td>74.8 Â± 1.02</td>\n",
       "      <td>0.3588 Â± 0.0246</td>\n",
       "      <td>0.8242 Â± 0.0942</td>\n",
       "      <td>0.5751 Â± 0.0553</td>\n",
       "      <td>0.5344 Â± 0.0323</td>\n",
       "      <td>0.2908 Â± 0.032</td>\n",
       "      <td>0.9146 Â± 0.1822</td>\n",
       "      <td>0.4328 Â± 0.044</td>\n",
       "      <td>0.4605 Â± 0.0826</td>\n",
       "      <td>69.6 Â± 1.83</td>\n",
       "      <td>89.07 Â± 0.25</td>\n",
       "      <td>88.27 Â± 0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sccnn_custom</th>\n",
       "      <td>82.19 Â± 1.07</td>\n",
       "      <td>70.88 Â± 2.25</td>\n",
       "      <td>48.75 Â± 3.98</td>\n",
       "      <td>76.17 Â± 6.63</td>\n",
       "      <td>76.6 Â± 1.75</td>\n",
       "      <td>77.12 Â± 1.07</td>\n",
       "      <td>74.19 Â± 2.86</td>\n",
       "      <td>88.18 Â± 0.32</td>\n",
       "      <td>73.28 Â± 3.45</td>\n",
       "      <td>0.3394 Â± 0.028</td>\n",
       "      <td>0.7937 Â± 0.1162</td>\n",
       "      <td>0.5527 Â± 0.0474</td>\n",
       "      <td>0.5112 Â± 0.0316</td>\n",
       "      <td>0.2825 Â± 0.0279</td>\n",
       "      <td>0.8976 Â± 0.1431</td>\n",
       "      <td>0.4278 Â± 0.0394</td>\n",
       "      <td>0.3553 Â± 0.0168</td>\n",
       "      <td>70.23 Â± 2.69</td>\n",
       "      <td>89.0 Â± 0.0</td>\n",
       "      <td>89.15 Â± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn</th>\n",
       "      <td>82.27 Â± 1.34</td>\n",
       "      <td>71.6 Â± 3.22</td>\n",
       "      <td>48.8 Â± nan</td>\n",
       "      <td>73.62 Â± 6.13</td>\n",
       "      <td>74.49 Â± 1.03</td>\n",
       "      <td>75.7 Â± 1.04</td>\n",
       "      <td>75.27 Â± 2.14</td>\n",
       "      <td>88.72 Â± 0.5</td>\n",
       "      <td>71.28 Â± 2.06</td>\n",
       "      <td>0.3186 Â± 0.0241</td>\n",
       "      <td>0.7122 Â± 0.0836</td>\n",
       "      <td>0.5208 Â± 0.0525</td>\n",
       "      <td>0.4648 Â± 0.043</td>\n",
       "      <td>0.2526 Â± 0.0247</td>\n",
       "      <td>0.9209 Â± 0.1993</td>\n",
       "      <td>0.3753 Â± 0.0432</td>\n",
       "      <td>0.5315 Â± 0.0401</td>\n",
       "      <td>71.24 Â± 1.68</td>\n",
       "      <td>90.32 Â± 0.11</td>\n",
       "      <td>88.79 Â± 0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset               Cora   IMDB-BINARY    IMDB-MULTI         MUTAG          NCI1        NCI109      PROTEINS        PubMed REDDIT-BINARY US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "Model                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "sccn          80.86 Â± 2.16  70.88 Â± 3.98  49.33 Â± 1.87   70.64 Â± 5.9  76.17 Â± 1.39  75.49 Â± 1.39  75.05 Â± 2.76  88.37 Â± 0.48   74.8 Â± 1.02              0.3588 Â± 0.0246           0.8242 Â± 0.0942           0.5751 Â± 0.0553          0.5344 Â± 0.0323               0.2908 Â± 0.032           0.9146 Â± 0.1822                   0.4328 Â± 0.044  0.4605 Â± 0.0826   69.6 Â± 1.83  89.07 Â± 0.25  88.27 Â± 0.14\n",
       "sccnn_custom  82.19 Â± 1.07  70.88 Â± 2.25  48.75 Â± 3.98  76.17 Â± 6.63   76.6 Â± 1.75  77.12 Â± 1.07  74.19 Â± 2.86  88.18 Â± 0.32  73.28 Â± 3.45               0.3394 Â± 0.028           0.7937 Â± 0.1162           0.5527 Â± 0.0474          0.5112 Â± 0.0316              0.2825 Â± 0.0279           0.8976 Â± 0.1431                  0.4278 Â± 0.0394  0.3553 Â± 0.0168  70.23 Â± 2.69    89.0 Â± 0.0  89.15 Â± 0.32\n",
       "scn           82.27 Â± 1.34   71.6 Â± 3.22    48.8 Â± nan  73.62 Â± 6.13  74.49 Â± 1.03   75.7 Â± 1.04  75.27 Â± 2.14   88.72 Â± 0.5  71.28 Â± 2.06              0.3186 Â± 0.0241           0.7122 Â± 0.0836           0.5208 Â± 0.0525           0.4648 Â± 0.043              0.2526 Â± 0.0247           0.9209 Â± 0.1993                  0.3753 Â± 0.0432  0.5315 Â± 0.0401  71.24 Â± 1.68  90.32 Â± 0.11  88.79 Â± 0.46"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"simplicial\"\n",
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(collect_bast_parameters)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "\n",
    "result_dict = result_dict.reset_index()\n",
    "\n",
    "rename_cols = {\n",
    "#'model.optimizer.lr': \"lr\",\n",
    "#'model.feature_encoder.out_channels':\"out_channels\",\n",
    "#'model.backbone.num_layers': 'num_layers',\n",
    "#'model.feature_encoder.proj_dropout': 'proj_dropout',\n",
    "#'dataset.parameters.batch_size': 'batch_size',\n",
    "'level_0': 'Dataset', 'level_1': 'Model', 'model/params/total': 'Num. parameters'}\n",
    "\n",
    "result_dict.rename(columns=rename_cols, inplace=True)\n",
    "result_dict['Num. parameters'] = (result_dict['Num. parameters'] /1000).round(2).apply(lambda x: f\"{x}K\")\n",
    "result_dict.to_csv(f\"best_parameters_{domain}.csv\")\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values='Num. parameters', aggfunc=\"first\"\n",
    ")\n",
    "result_dict.to_csv(f\"model_sizes_{domain}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>IMDB-BINARY</th>\n",
       "      <th>IMDB-MULTI</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>REDDIT-BINARY</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sccn</th>\n",
       "      <td>155.88K</td>\n",
       "      <td>563.07K</td>\n",
       "      <td>545.16K</td>\n",
       "      <td>398.85K</td>\n",
       "      <td>131.84K</td>\n",
       "      <td>135.75K</td>\n",
       "      <td>397.31K</td>\n",
       "      <td>457.99K</td>\n",
       "      <td>25.44K</td>\n",
       "      <td>43.52K</td>\n",
       "      <td>11.52K</td>\n",
       "      <td>11.52K</td>\n",
       "      <td>11.52K</td>\n",
       "      <td>268.03K</td>\n",
       "      <td>11.52K</td>\n",
       "      <td>11.52K</td>\n",
       "      <td>617.86K</td>\n",
       "      <td>782.34K</td>\n",
       "      <td>25.15K</td>\n",
       "      <td>612.5K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sccnn_custom</th>\n",
       "      <td>164.17K</td>\n",
       "      <td>285.83K</td>\n",
       "      <td>121.22K</td>\n",
       "      <td>27.11K</td>\n",
       "      <td>188.99K</td>\n",
       "      <td>49.54K</td>\n",
       "      <td>26.72K</td>\n",
       "      <td>605.06K</td>\n",
       "      <td>53.19K</td>\n",
       "      <td>415.1K</td>\n",
       "      <td>26.98K</td>\n",
       "      <td>415.1K</td>\n",
       "      <td>415.1K</td>\n",
       "      <td>105.15K</td>\n",
       "      <td>415.1K</td>\n",
       "      <td>105.15K</td>\n",
       "      <td>1453.82K</td>\n",
       "      <td>893.13K</td>\n",
       "      <td>33.44K</td>\n",
       "      <td>240.53K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn</th>\n",
       "      <td>144.62K</td>\n",
       "      <td>52.16K</td>\n",
       "      <td>92.74K</td>\n",
       "      <td>20.03K</td>\n",
       "      <td>94.98K</td>\n",
       "      <td>26.08K</td>\n",
       "      <td>10.24K</td>\n",
       "      <td>134.4K</td>\n",
       "      <td>7.84K</td>\n",
       "      <td>27.14K</td>\n",
       "      <td>103.42K</td>\n",
       "      <td>27.14K</td>\n",
       "      <td>16.64K</td>\n",
       "      <td>27.14K</td>\n",
       "      <td>16.64K</td>\n",
       "      <td>27.14K</td>\n",
       "      <td>24.42K</td>\n",
       "      <td>737.29K</td>\n",
       "      <td>51.97K</td>\n",
       "      <td>415.89K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Cora IMDB-BINARY IMDB-MULTI    MUTAG     NCI1   NCI109 PROTEINS   PubMed REDDIT-BINARY US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate      ZINC citeseer minesweeper roman_empire\n",
       "Model                                                                                                                                                                                                                                                                                                                                                \n",
       "sccn          155.88K     563.07K    545.16K  398.85K  131.84K  135.75K  397.31K  457.99K        25.44K                       43.52K                    11.52K                    11.52K                   11.52K                      268.03K                    11.52K                           11.52K   617.86K  782.34K      25.15K       612.5K\n",
       "sccnn_custom  164.17K     285.83K    121.22K   27.11K  188.99K   49.54K   26.72K  605.06K        53.19K                       415.1K                    26.98K                    415.1K                   415.1K                      105.15K                    415.1K                          105.15K  1453.82K  893.13K      33.44K      240.53K\n",
       "scn           144.62K      52.16K     92.74K   20.03K   94.98K   26.08K   10.24K   134.4K         7.84K                       27.14K                   103.42K                    27.14K                   16.64K                       27.14K                    16.64K                           27.14K    24.42K  737.29K      51.97K      415.89K"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate signal down comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: IMDB-MULTI, Model: sccn\n",
      "Initial number of rows, 320\n",
      "Final number of rows , 316\n",
      "Rows that had NANs number of rows , -4\n",
      "Dataset: IMDB-MULTI, Model: scn\n",
      "Initial number of rows, 73\n",
      "Final number of rows , 71\n",
      "Rows that had NANs number of rows , -2\n",
      "Dataset: IMDB-MULTI, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: IMDB-BINARY, Model: sccn\n",
      "Initial number of rows, 309\n",
      "Final number of rows , 307\n",
      "Rows that had NANs number of rows , -2\n",
      "Dataset: IMDB-BINARY, Model: scn\n",
      "Initial number of rows, 74\n",
      "Final number of rows , 73\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: IMDB-BINARY, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: ZINC, Model: sccn\n",
      "Initial number of rows, 451\n",
      "Final number of rows , 439\n",
      "Rows that had NANs number of rows , -12\n",
      "Dataset: ZINC, Model: scn\n",
      "Initial number of rows, 370\n",
      "Final number of rows , 351\n",
      "Rows that had NANs number of rows , -19\n",
      "Dataset: ZINC, Model: sccnn_custom\n",
      "Initial number of rows, 465\n",
      "Final number of rows , 465\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: minesweeper, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 478\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: minesweeper, Model: scn\n",
      "Initial number of rows, 721\n",
      "Final number of rows , 721\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: minesweeper, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: NCI1, Model: sccn\n",
      "Initial number of rows, 689\n",
      "Final number of rows , 679\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI1, Model: scn\n",
      "Initial number of rows, 533\n",
      "Final number of rows , 531\n",
      "Rows that had NANs number of rows , -2\n",
      "Dataset: NCI1, Model: sccnn_custom\n",
      "Initial number of rows, 647\n",
      "Final number of rows , 646\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: NCI109, Model: sccn\n",
      "Initial number of rows, 679\n",
      "Final number of rows , 669\n",
      "Rows that had NANs number of rows , -10\n",
      "Dataset: NCI109, Model: scn\n",
      "Initial number of rows, 537\n",
      "Final number of rows , 537\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: NCI109, Model: sccnn_custom\n",
      "Initial number of rows, 639\n",
      "Final number of rows , 638\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: roman_empire, Model: sccn\n",
      "Initial number of rows, 469\n",
      "Final number of rows , 469\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: roman_empire, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PROTEINS, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: PubMed, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: citeseer, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: citeseer, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: sccn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: Cora, Model: scn\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 239\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: Cora, Model: sccnn_custom\n",
      "Initial number of rows, 240\n",
      "Final number of rows , 240\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: scn\n",
      "Initial number of rows, 461\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-UnemploymentRate, Model: sccnn_custom\n",
      "Initial number of rows, 481\n",
      "Final number of rows , 481\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccn\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BachelorRate, Model: scn\n",
      "Initial number of rows, 462\n",
      "Final number of rows , 459\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BachelorRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 959\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: MUTAG, Model: scn\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: MUTAG, Model: sccnn_custom\n",
      "Initial number of rows, 960\n",
      "Final number of rows , 960\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: sccn\n",
      "Initial number of rows, 479\n",
      "Final number of rows , 479\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-DeathRate, Model: scn\n",
      "Initial number of rows, 448\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: US-county-demos-DeathRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: sccn\n",
      "Initial number of rows, 456\n",
      "Final number of rows , 456\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-BirthRate, Model: scn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 447\n",
      "Rows that had NANs number of rows , -3\n",
      "Dataset: US-county-demos-BirthRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccn\n",
      "Initial number of rows, 450\n",
      "Final number of rows , 450\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: scn\n",
      "Initial number of rows, 460\n",
      "Final number of rows , 460\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MigraRate, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccn\n",
      "Initial number of rows, 434\n",
      "Final number of rows , 434\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-MedianIncome, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccn\n",
      "Initial number of rows, 454\n",
      "Final number of rows , 454\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: scn\n",
      "Initial number of rows, 463\n",
      "Final number of rows , 463\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: US-county-demos-Election, Model: sccnn_custom\n",
      "Initial number of rows, 480\n",
      "Final number of rows , 480\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: REDDIT-BINARY, Model: sccn\n",
      "Initial number of rows, 46\n",
      "Final number of rows , 45\n",
      "Rows that had NANs number of rows , -1\n",
      "Dataset: REDDIT-BINARY, Model: scn\n",
      "Initial number of rows, 60\n",
      "Final number of rows , 60\n",
      "Rows that had NANs number of rows , 0\n",
      "Dataset: REDDIT-BINARY, Model: sccnn_custom\n",
      "Initial number of rows, 46\n",
      "Final number of rows , 45\n",
      "Rows that had NANs number of rows , -1\n"
     ]
    }
   ],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        init_num_of_rows = subset.shape[0]\n",
    "        print(f'Initial number of rows, {init_num_of_rows}')\n",
    "\n",
    "        # Find 'NaN' in performance columns\n",
    "        # for each column find number of rows with 'NaN' string\n",
    "        total_performance_nan = 0\n",
    "        for column in performance_columns:\n",
    "            # Find the number of NaN string in the column\n",
    "            num_nan = subset[column].apply(lambda x: x == 'NaN')\n",
    "            num_nan = num_nan.sum()\n",
    "            total_performance_nan += num_nan        \n",
    "    \n",
    "        if total_performance_nan > 0:\n",
    "          \n",
    "            nan_rows = subset[performance_columns].eq('NaN')\n",
    "            nan_rows = nan_rows.sum(axis=1)\n",
    "            # Drop every rows where 'NaN' string is present\n",
    "            subset = subset[~nan_rows.gt(0)]\n",
    "           \n",
    "        # Ensure that the performance columns are of type float\n",
    "        subset[performance_columns] = subset[performance_columns].astype(float)\n",
    "    \n",
    "        for column in performance_columns:\n",
    "            if subset[column].isna().sum() > 0:  \n",
    "                subset = subset[~subset[column].isna()]\n",
    "\n",
    "        final_num_of_rows = subset.shape[0]  \n",
    "        print(f'Final number of rows , {final_num_of_rows}')\n",
    "        print(f'Rows that had NANs number of rows , {final_num_of_rows - init_num_of_rows}')\n",
    "\n",
    "        # --------WORKOUT NAN--------\n",
    "\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "        if sorted(list(aggregated['model.readout.readout_name'].unique())) == sorted(['NoReadOut', 'PropagateSignalDown']):\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                agg_sub = aggregated[aggregated['model.readout.readout_name'] == prop_type]\n",
    "                agg_sub = agg_sub.sort_values(\n",
    "                    by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "                )\n",
    "                \n",
    "                final_best = agg_sub.head(1)\n",
    "                if final_best[(eval_metric, \"mean\")].any(): \n",
    "                    best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                        \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                        \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "                    }\n",
    "\n",
    "                    # Extract best runs: \n",
    "                    best_params = {}\n",
    "                    for col in sweeped_columns:\n",
    "                        best_params[col] = final_best[(col, '')].item()\n",
    "                    \n",
    "                    hp_runs[dataset][model] = subset.copy()\n",
    "                    \n",
    "                    # Start with the entire DataFrame\n",
    "                    filtered_subset = subset.copy()\n",
    "\n",
    "                    # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "                    for param, value in best_params.items():\n",
    "                        filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "                    best_runs[dataset][model] = filtered_subset\n",
    "                \n",
    "                else: \n",
    "                    best_results[dataset][model] = {\n",
    "                        \"mean\": np.nan,\n",
    "                        \"std\": np.nan,\n",
    "                        \"prop_type\": prop_type\n",
    "                    }\n",
    "        else:\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                            \"mean\": np.nan,\n",
    "                            \"std\": np.nan,\n",
    "                        }\n",
    "\n",
    "       \n",
    "\n",
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']} Â± {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")\n",
    "result_dict.reset_index(inplace=True)\n",
    "\n",
    "result_dict['ReadOut'] = result_dict['Model'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "result_dict['Model'] = result_dict['Model'].apply(lambda x: x.split('(')[0])\n",
    "\n",
    "result_dict.sort_values(by=['Model','ReadOut'], inplace=True)\n",
    "\n",
    "# columns = ['Model',\n",
    "# 'ReadOut',\n",
    "#  'Cora',\n",
    "#  'MUTAG',\n",
    "#  'NCI1',\n",
    "#  'NCI109',\n",
    "#  'PROTEINS',\n",
    "#  'PubMed',\n",
    "#  'US-county-demos-BachelorRate',\n",
    "#  'US-county-demos-BirthRate',\n",
    "#  'US-county-demos-DeathRate',\n",
    "#  'US-county-demos-Election',\n",
    "#  'US-county-demos-MedianIncome',\n",
    "#  'US-county-demos-MigraRate',\n",
    "#  'US-county-demos-UnemploymentRate',\n",
    "#  'ZINC',\n",
    "#  'citeseer',\n",
    "#  'minesweeper',\n",
    "#  'roman_empire',]\n",
    "# result_dict = result_dict[columns]\n",
    "result_dict.to_csv(f\"ablation_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Cora</th>\n",
       "      <th>IMDB-BINARY</th>\n",
       "      <th>IMDB-MULTI</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>REDDIT-BINARY</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "      <th>ReadOut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sccn</td>\n",
       "      <td>80.86 Â± 2.16</td>\n",
       "      <td>69.68 Â± 2.42</td>\n",
       "      <td>46.45 Â± 1.78</td>\n",
       "      <td>70.64 Â± 5.9</td>\n",
       "      <td>76.42 Â± 0.88</td>\n",
       "      <td>75.49 Â± 1.39</td>\n",
       "      <td>75.05 Â± 2.76</td>\n",
       "      <td>88.04 Â± 0.51</td>\n",
       "      <td>73.52 Â± 1.53</td>\n",
       "      <td>0.3588 Â± 0.0246</td>\n",
       "      <td>0.8242 Â± 0.0942</td>\n",
       "      <td>0.5751 Â± 0.0553</td>\n",
       "      <td>0.5344 Â± 0.0323</td>\n",
       "      <td>0.2868 Â± 0.0276</td>\n",
       "      <td>0.9146 Â± 0.1822</td>\n",
       "      <td>0.4328 Â± 0.044</td>\n",
       "      <td>0.5538 Â± 0.0111</td>\n",
       "      <td>69.6 Â± 1.83</td>\n",
       "      <td>88.85 Â± 0.0</td>\n",
       "      <td>88.2 Â± 0.22</td>\n",
       "      <td>NoReadOut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sccn</td>\n",
       "      <td>80.06 Â± 1.66</td>\n",
       "      <td>69.3 Â± 6.81</td>\n",
       "      <td>47.31 Â± 3.12</td>\n",
       "      <td>73.62 Â± 4.41</td>\n",
       "      <td>76.17 Â± 1.39</td>\n",
       "      <td>75.31 Â± 1.36</td>\n",
       "      <td>74.34 Â± 3.17</td>\n",
       "      <td>88.37 Â± 0.48</td>\n",
       "      <td>74.44 Â± 1.74</td>\n",
       "      <td>0.341 Â± 0.0249</td>\n",
       "      <td>0.8264 Â± 0.1018</td>\n",
       "      <td>0.5629 Â± 0.0444</td>\n",
       "      <td>0.5686 Â± 0.0247</td>\n",
       "      <td>0.2908 Â± 0.032</td>\n",
       "      <td>0.9303 Â± 0.172</td>\n",
       "      <td>0.4734 Â± 0.0377</td>\n",
       "      <td>0.4605 Â± 0.0826</td>\n",
       "      <td>68.86 Â± 2.4</td>\n",
       "      <td>89.07 Â± 0.25</td>\n",
       "      <td>88.27 Â± 0.14</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>82.19 Â± 1.07</td>\n",
       "      <td>70.88 Â± 2.25</td>\n",
       "      <td>48.75 Â± 3.98</td>\n",
       "      <td>76.17 Â± 6.63</td>\n",
       "      <td>76.6 Â± 1.75</td>\n",
       "      <td>77.12 Â± 1.07</td>\n",
       "      <td>74.19 Â± 2.86</td>\n",
       "      <td>88.18 Â± 0.32</td>\n",
       "      <td>73.0 Â± 0.2</td>\n",
       "      <td>0.3394 Â± 0.028</td>\n",
       "      <td>0.7937 Â± 0.1162</td>\n",
       "      <td>0.5527 Â± 0.0474</td>\n",
       "      <td>0.5112 Â± 0.0316</td>\n",
       "      <td>0.2825 Â± 0.0279</td>\n",
       "      <td>0.8976 Â± 0.1431</td>\n",
       "      <td>0.4278 Â± 0.0394</td>\n",
       "      <td>0.3562 Â± 0.013</td>\n",
       "      <td>70.23 Â± 2.69</td>\n",
       "      <td>87.4 Â± 0.0</td>\n",
       "      <td>89.15 Â± 0.32</td>\n",
       "      <td>NoReadOut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sccnn_custom</td>\n",
       "      <td>80.65 Â± 2.39</td>\n",
       "      <td>69.28 Â± 5.69</td>\n",
       "      <td>46.67 Â± 3.13</td>\n",
       "      <td>70.64 Â± 3.16</td>\n",
       "      <td>75.6 Â± 2.45</td>\n",
       "      <td>75.43 Â± 1.94</td>\n",
       "      <td>74.98 Â± 1.92</td>\n",
       "      <td>87.78 Â± 0.58</td>\n",
       "      <td>73.5 Â± 0.42</td>\n",
       "      <td>0.3449 Â± 0.0314</td>\n",
       "      <td>0.8251 Â± 0.1184</td>\n",
       "      <td>0.579 Â± 0.0541</td>\n",
       "      <td>0.557 Â± 0.041</td>\n",
       "      <td>0.3073 Â± 0.0316</td>\n",
       "      <td>0.9274 Â± 0.1711</td>\n",
       "      <td>0.4538 Â± 0.0428</td>\n",
       "      <td>0.3553 Â± 0.0168</td>\n",
       "      <td>69.03 Â± 2.01</td>\n",
       "      <td>89.0 Â± 0.0</td>\n",
       "      <td>88.73 Â± 0.12</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scn</td>\n",
       "      <td>82.27 Â± 1.34</td>\n",
       "      <td>67.52 Â± 4.5</td>\n",
       "      <td>49.87 Â± 1.64</td>\n",
       "      <td>71.49 Â± 2.43</td>\n",
       "      <td>75.27 Â± 1.57</td>\n",
       "      <td>74.58 Â± 1.29</td>\n",
       "      <td>75.27 Â± 2.14</td>\n",
       "      <td>88.72 Â± 0.5</td>\n",
       "      <td>71.28 Â± 2.06</td>\n",
       "      <td>0.3186 Â± 0.0241</td>\n",
       "      <td>0.7122 Â± 0.0836</td>\n",
       "      <td>0.5208 Â± 0.0525</td>\n",
       "      <td>0.4648 Â± 0.043</td>\n",
       "      <td>0.2521 Â± 0.0253</td>\n",
       "      <td>0.9209 Â± 0.1993</td>\n",
       "      <td>0.3753 Â± 0.0432</td>\n",
       "      <td>0.6037 Â± nan</td>\n",
       "      <td>71.24 Â± 1.68</td>\n",
       "      <td>90.32 Â± 0.11</td>\n",
       "      <td>85.89 Â± 0.34</td>\n",
       "      <td>NoReadOut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scn</td>\n",
       "      <td>79.91 Â± 1.18</td>\n",
       "      <td>65.6 Â± nan</td>\n",
       "      <td>48.0 Â± 3.67</td>\n",
       "      <td>73.62 Â± 6.13</td>\n",
       "      <td>74.49 Â± 1.03</td>\n",
       "      <td>75.7 Â± 1.04</td>\n",
       "      <td>74.77 Â± 1.69</td>\n",
       "      <td>88.62 Â± 0.44</td>\n",
       "      <td>69.68 Â± 4.0</td>\n",
       "      <td>0.3205 Â± 0.0271</td>\n",
       "      <td>0.7985 Â± 0.1062</td>\n",
       "      <td>0.5635 Â± 0.0457</td>\n",
       "      <td>0.5091 Â± 0.0345</td>\n",
       "      <td>0.2723 Â± 0.0174</td>\n",
       "      <td>0.9619 Â± 0.2329</td>\n",
       "      <td>0.4131 Â± 0.0297</td>\n",
       "      <td>0.5315 Â± 0.0401</td>\n",
       "      <td>70.4 Â± 1.53</td>\n",
       "      <td>90.27 Â± 0.36</td>\n",
       "      <td>88.79 Â± 0.46</td>\n",
       "      <td>PropagateSignalDown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset          Model          Cora   IMDB-BINARY    IMDB-MULTI         MUTAG          NCI1        NCI109      PROTEINS        PubMed REDDIT-BINARY US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire              ReadOut\n",
       "0                sccn   80.86 Â± 2.16  69.68 Â± 2.42  46.45 Â± 1.78   70.64 Â± 5.9  76.42 Â± 0.88  75.49 Â± 1.39  75.05 Â± 2.76  88.04 Â± 0.51  73.52 Â± 1.53              0.3588 Â± 0.0246           0.8242 Â± 0.0942           0.5751 Â± 0.0553          0.5344 Â± 0.0323              0.2868 Â± 0.0276           0.9146 Â± 0.1822                   0.4328 Â± 0.044  0.5538 Â± 0.0111   69.6 Â± 1.83   88.85 Â± 0.0   88.2 Â± 0.22            NoReadOut\n",
       "1                sccn   80.06 Â± 1.66   69.3 Â± 6.81  47.31 Â± 3.12  73.62 Â± 4.41  76.17 Â± 1.39  75.31 Â± 1.36  74.34 Â± 3.17  88.37 Â± 0.48  74.44 Â± 1.74               0.341 Â± 0.0249           0.8264 Â± 0.1018           0.5629 Â± 0.0444          0.5686 Â± 0.0247               0.2908 Â± 0.032            0.9303 Â± 0.172                  0.4734 Â± 0.0377  0.4605 Â± 0.0826   68.86 Â± 2.4  89.07 Â± 0.25  88.27 Â± 0.14  PropagateSignalDown\n",
       "2        sccnn_custom   82.19 Â± 1.07  70.88 Â± 2.25  48.75 Â± 3.98  76.17 Â± 6.63   76.6 Â± 1.75  77.12 Â± 1.07  74.19 Â± 2.86  88.18 Â± 0.32    73.0 Â± 0.2               0.3394 Â± 0.028           0.7937 Â± 0.1162           0.5527 Â± 0.0474          0.5112 Â± 0.0316              0.2825 Â± 0.0279           0.8976 Â± 0.1431                  0.4278 Â± 0.0394   0.3562 Â± 0.013  70.23 Â± 2.69    87.4 Â± 0.0  89.15 Â± 0.32            NoReadOut\n",
       "3        sccnn_custom   80.65 Â± 2.39  69.28 Â± 5.69  46.67 Â± 3.13  70.64 Â± 3.16   75.6 Â± 2.45  75.43 Â± 1.94  74.98 Â± 1.92  87.78 Â± 0.58   73.5 Â± 0.42              0.3449 Â± 0.0314           0.8251 Â± 0.1184            0.579 Â± 0.0541            0.557 Â± 0.041              0.3073 Â± 0.0316           0.9274 Â± 0.1711                  0.4538 Â± 0.0428  0.3553 Â± 0.0168  69.03 Â± 2.01    89.0 Â± 0.0  88.73 Â± 0.12  PropagateSignalDown\n",
       "4                 scn   82.27 Â± 1.34   67.52 Â± 4.5  49.87 Â± 1.64  71.49 Â± 2.43  75.27 Â± 1.57  74.58 Â± 1.29  75.27 Â± 2.14   88.72 Â± 0.5  71.28 Â± 2.06              0.3186 Â± 0.0241           0.7122 Â± 0.0836           0.5208 Â± 0.0525           0.4648 Â± 0.043              0.2521 Â± 0.0253           0.9209 Â± 0.1993                  0.3753 Â± 0.0432     0.6037 Â± nan  71.24 Â± 1.68  90.32 Â± 0.11  85.89 Â± 0.34            NoReadOut\n",
       "5                 scn   79.91 Â± 1.18    65.6 Â± nan   48.0 Â± 3.67  73.62 Â± 6.13  74.49 Â± 1.03   75.7 Â± 1.04  74.77 Â± 1.69  88.62 Â± 0.44   69.68 Â± 4.0              0.3205 Â± 0.0271           0.7985 Â± 0.1062           0.5635 Â± 0.0457          0.5091 Â± 0.0345              0.2723 Â± 0.0174           0.9619 Â± 0.2329                  0.4131 Â± 0.0297  0.5315 Â± 0.0401   70.4 Â± 1.53  90.27 Â± 0.36  88.79 Â± 0.46  PropagateSignalDown"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
