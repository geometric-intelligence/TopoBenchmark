{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api()\n",
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"/home/lev/projects/TopoBenchmarkX/big_csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "project_name = \"TopoBenchmarkX_Simplicial\"  \n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "if project_name not in csv_names:\n",
    "    runs = api.runs(f\"{user}/{project_name}\")\n",
    "\n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs:\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        )\n",
    "\n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "    )\n",
    "\n",
    "    runs_df.to_csv(f\"{user}_{project_name}.csv\")\n",
    "else:\n",
    "    runs_df = pd.read_csv(f\"{user}_{project_name}.csv\", index_col=0)\n",
    "\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "\n",
    "\n",
    "for row in runs_df.iloc:\n",
    "    row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "df_init = df.copy()\n",
    "\n",
    "# Get average epoch run time\n",
    "df[\"epoch_run_time\"] = df[\"_runtime\"] / df[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\"]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate tables to obtain full hp space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "additiona_runs = pd.read_csv(f'gbg141_{project_name}.csv', index_col=0)\n",
    "df = pd.concat([df, additiona_runs], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select models that have finished the runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout us_demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every rows where df['dataset.parameters.data_name'] == 'US-county-demos' extend the 'dataset.parameters.data_name' with dataset.parameters.task_variable \n",
    "# and set it to 'US-county-demos' + '-' + dataset.parameters.task_variable\n",
    "df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] = df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.data_name'] + '-' + df.loc[df['dataset.parameters.data_name'] == 'US-county-demos', 'dataset.parameters.task_variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/accuracy', '_wandb', 'train/auroc', 'test/accuracy', 'val/precision']\n",
      "['train/loss', 'train/recall', 'val/accuracy', 'train/precision', 'epoch']\n",
      "['lr-Adam', 'test/loss', 'test/auroc', 'trainer/global_step', 'test/precision']\n",
      "['val/loss', 'val/auroc', 'val/recall', 'test/recall', '_step']\n",
      "['_runtime', '_timestamp', 'seed', 'tags', 'extras']\n",
      "['trainer', 'ckpt_path', 'task_name', 'model/params/total', 'model/params/trainable']\n",
      "['model/params/non_trainable', 'test/mse', 'train/mae', 'val/mae', 'val/mse']\n",
      "['test/mae', 'train/mse', 'epoch_run_time', 'model.compile', 'model._target_']\n",
      "['model.model_name', 'model.model_domain', 'model.loss.task', 'model.loss._target_', 'model.loss.loss_type']\n",
      "['model.readout._target_', 'model.readout.hidden_dim', 'model.readout.readout_name', 'model.readout.num_cell_dimensions', 'model.backbone._target_']\n",
      "['model.backbone.n_layers', 'model.backbone.sc_order', 'model.backbone.aggr_norm', 'model.backbone.conv_order', 'model.backbone.update_func']\n",
      "['model.backbone.in_channels_all', 'model.backbone.hidden_channels_all', 'model.optimizer.lr', 'model.optimizer._target_', 'model.optimizer._partial_']\n",
      "['model.optimizer.weight_decay', 'model.scheduler._target_', 'model.scheduler._partial_', 'model.scheduler.last_epoch', 'model.scheduler.total_iters']\n",
      "['model.head_model._target_', 'model.head_model.task_level', 'model.head_model.in_channels', 'model.head_model.out_channels', 'model.head_model.pooling_type']\n",
      "['model.head_model.head_model_name', 'model.feature_encoder._target_', 'model.feature_encoder.in_channels', 'model.feature_encoder.encoder_name', 'model.feature_encoder.out_channels']\n",
      "['model.feature_encoder.proj_dropout', 'model.feature_encoder.selected_dimensions', 'model.backbone_wrapper._target_', 'model.backbone_wrapper._partial_', 'model.backbone_wrapper.out_channels']\n",
      "['model.backbone_wrapper.wrapper_name', 'model.backbone_wrapper.num_cell_dimensions', 'model.backbone.in_channels_0', 'model.backbone.in_channels_1', 'model.backbone.in_channels_2']\n",
      "['model.backbone.channels', 'model.backbone.max_rank', 'dataset._target_', 'dataset.parameters.k', 'dataset.parameters.task']\n",
      "['dataset.parameters.data_dir', 'dataset.parameters.data_name', 'dataset.parameters.data_seed', 'dataset.parameters.data_type', 'dataset.parameters.loss_type']\n",
      "['dataset.parameters.batch_size', 'dataset.parameters.pin_memory', 'dataset.parameters.split_type', 'dataset.parameters.task_level', 'dataset.parameters.train_prop']\n",
      "['dataset.parameters.data_domain', 'dataset.parameters.num_classes', 'dataset.parameters.num_workers', 'dataset.parameters.num_features', 'dataset.parameters.data_split_dir']\n",
      "['dataset.parameters.monitor_metric', 'dataset.transforms.graph2simplicial_lifting.signed', 'dataset.transforms.graph2simplicial_lifting._target_', 'dataset.transforms.graph2simplicial_lifting.complex_dim', 'dataset.transforms.graph2simplicial_lifting.transform_name']\n",
      "['dataset.transforms.graph2simplicial_lifting.transform_type', 'dataset.transforms.graph2simplicial_lifting.feature_lifting', 'dataset.transforms.graph2simplicial_lifting.preserve_edge_attr', 'dataset.parameters.force_reload', 'dataset.parameters.max_node_degree']\n",
      "['dataset.transforms.data_manipulations._target_', 'dataset.transforms.data_manipulations.transform_name', 'dataset.transforms.data_manipulations.transform_type', 'dataset.transforms.data_manipulations.selected_fields', 'dataset.transforms.one_hot_node_degree_features._target_']\n",
      "['dataset.transforms.one_hot_node_degree_features.max_degree', 'dataset.transforms.one_hot_node_degree_features.degrees_fields', 'dataset.transforms.one_hot_node_degree_features.transform_name', 'dataset.transforms.one_hot_node_degree_features.transform_type', 'dataset.transforms.one_hot_node_degree_features.features_fields']\n",
      "['dataset.parameters.year', 'dataset.parameters.task_variable', 'dataset.parameters.max_dim_if_lifted', 'dataset.parameters.preserve_edge_attr_if_lifted', 'callbacks.model_summary._target_']\n",
      "['callbacks.model_summary.max_depth', 'callbacks.early_stopping.mode', 'callbacks.early_stopping.strict', 'callbacks.early_stopping.monitor', 'callbacks.early_stopping.verbose']\n",
      "['callbacks.early_stopping._target_', 'callbacks.early_stopping.patience', 'callbacks.early_stopping.min_delta', 'callbacks.early_stopping.check_finite', 'callbacks.early_stopping.stopping_threshold']\n",
      "['callbacks.early_stopping.divergence_threshold', 'callbacks.early_stopping.check_on_train_epoch_end', 'callbacks.model_checkpoint.mode', 'callbacks.model_checkpoint.dirpath', 'callbacks.model_checkpoint.monitor']\n",
      "['callbacks.model_checkpoint.verbose', 'callbacks.model_checkpoint._target_', 'callbacks.model_checkpoint.filename', 'callbacks.model_checkpoint.save_last', 'callbacks.model_checkpoint.save_top_k']\n",
      "['callbacks.model_checkpoint.every_n_epochs', 'callbacks.model_checkpoint.save_weights_only', 'callbacks.model_checkpoint.every_n_train_steps', 'callbacks.model_checkpoint.train_time_interval', 'callbacks.model_checkpoint.auto_insert_metric_name']\n",
      "['callbacks.model_checkpoint.save_on_train_epoch_end', 'callbacks.rich_progress_bar._target_', 'callbacks.learning_rate_monitor._target_', 'callbacks.learning_rate_monitor.logging_interval', 'paths.log_dir']\n",
      "['paths.data_dir', 'paths.root_dir', 'paths.work_dir', 'paths.output_dir', 'dataset.transforms.one_hot_node_degree_features.max_degrees']\n"
     ]
    }
   ],
   "source": [
    "# Print all columns 10 per line\n",
    "for i in range(0, len(df.columns), 5):\n",
    "    print(list(df.columns[i:i + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NCI109' 'NCI1' 'minesweeper' nan 'roman_empire' 'ZINC' 'PROTEINS'\n",
      " 'PubMed' 'citeseer' 'Cora' 'US-county-demos-UnemploymentRate'\n",
      " 'US-county-demos-BachelorRate' 'MUTAG' 'US-county-demos-DeathRate'\n",
      " 'US-county-demos-BirthRate' 'US-county-demos-MigraRate'\n",
      " 'US-county-demos-MedianIncome' 'US-county-demos-Election']\n",
      "Num unique datasets: 18\n"
     ]
    }
   ],
   "source": [
    "print(df['dataset.parameters.data_name'].unique())\n",
    "print(\"Num unique datasets:\", len(df['dataset.parameters.data_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sccnn_custom' nan 'scn' 'sccn']\n"
     ]
    }
   ],
   "source": [
    "print(df['model.model_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve batch problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: sccnn_custom\n",
      "[1.]\n",
      "[1.]\n",
      "MODEL: scn\n",
      "[]\n",
      "[]\n",
      "MODEL: sccn\n",
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "datasets = ['minesweeper', 'roman_empire']\n",
    "models = ['sccnn_custom', 'scn', 'sccn']\n",
    "# For the following models and datasets I mistook the batch size, it should be 1, instead of 256 or 128\n",
    "# Keep the run where batch size is 128 and then change the batch size to 1\n",
    "for model in models:\n",
    "    print(\"MODEL:\", model)\n",
    "    for dataset in datasets:\n",
    "\n",
    "        # Change the batch size to 1 when it is 128\n",
    "        \n",
    "        print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), 'dataset.parameters.batch_size'].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve issue with projection dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  0.25  nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['model.feature_encoder.proj_dropout'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where model.feature_encoder.proj_dropout is [0.5  0.25]\n",
    "df = df[df['model.feature_encoder.proj_dropout'].isin([0.5, 0.25])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sccnn_custom\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64.  32. 128.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 3. 0. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[ 64.  32. 128.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0. 3. 7. 9. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[ 23.   5.  42.   3. 150.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: scn\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[]\n",
      "Column: model.backbone.n_layers\n",
      "[]\n",
      "Column: model.readout.readout_name\n",
      "[]\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[]\n",
      "Column: dataset.parameters.batch_size\n",
      "[]\n",
      "Column: dataset.parameters.data_seed\n",
      "[]\n",
      "Column: seed\n",
      "[]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n",
      "Model: sccn\n",
      "Dataset: NCI109\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1. 4. 3.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.25 0.5 ]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7. 9. 0. 3. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: NCI1\n",
      "Column: model.optimizer.lr\n",
      "[0.01]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[1. 2. 4. 3.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[3. 0. 7. 9. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: minesweeper\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[5. 7. 0. 3. 9.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: roman_empire\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7. 0. 5. 9. 3.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: ZINC\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 2.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[128. 256.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[0.]\n",
      "Column: seed\n",
      "[  5.   3. 150.  42.  23.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PROTEINS\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[256. 128.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[7. 3. 0. 9. 5.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: PubMed\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: citeseer\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: Cora\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-UnemploymentRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BachelorRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: MUTAG\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[64. 32.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 0. 5. 3.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-DeathRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-BirthRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MigraRate\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-MedianIncome\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['NoReadOut' 'PropagateSignalDown']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "Dataset: US-county-demos-Election\n",
      "Column: model.optimizer.lr\n",
      "[0.001 0.01 ]\n",
      "Column: model.feature_encoder.out_channels\n",
      "[128.  64.  32.]\n",
      "Column: model.backbone.n_layers\n",
      "[4. 3. 2. 1.]\n",
      "Column: model.readout.readout_name\n",
      "['PropagateSignalDown' 'NoReadOut']\n",
      "Column: dataset.transforms.graph2simplicial_lifting.signed\n",
      "[True]\n",
      "Column: model.feature_encoder.proj_dropout\n",
      "[0.5  0.25]\n",
      "Column: dataset.parameters.batch_size\n",
      "[1.]\n",
      "Column: dataset.parameters.data_seed\n",
      "[9. 7. 5. 3. 0.]\n",
      "Column: seed\n",
      "[42.]\n",
      "---------------NEW DATASET------------------\n",
      "---------------NEW MODEL------------------\n"
     ]
    }
   ],
   "source": [
    "# Sweeped parameters: \n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'dataset.parameters.data_seed',\n",
    "    'seed',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# For each model and dataset go over all the sweeped parameters and print the unique values\n",
    "for model in df['model.model_name'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in df['dataset.parameters.data_name'].unique():\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for column in sweeped_columns:\n",
    "            print(f\"Column: {column}\")\n",
    "            print(df.loc[(df['model.model_name'] == model) & (df['dataset.parameters.data_name'] == dataset), column].unique())\n",
    "        \n",
    "        print('---------------NEW DATASET------------------')\n",
    "    print('---------------NEW MODEL------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    'model.optimizer.lr', \n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.readout.readout_name',\n",
    "    'dataset.transforms.graph2simplicial_lifting.signed',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'dataset.parameters.batch_size',\n",
    "]\n",
    "run_columns = ['dataset.parameters.data_seed','seed']\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'dataset.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'REDDIT-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'citeseer': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'roman_empire': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'amazon_ratings': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    \n",
    "    'tolokers': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'questions': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'minesweeper': {'optim_metric': 'val/auroc', 'eval_metric': 'test/auroc', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "    'ZINC': {'optim_metric': 'val/mse', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    \n",
    "    'US-county-demos-UnemploymentRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BachelorRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-DeathRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-BirthRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MigraRate': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-MedianIncome': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'US-county-demos-Election': {'optim_metric': 'val/mse', 'eval_metric': 'test/mse', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Get the best result\n",
    "        final_best = aggregated.head(1)\n",
    "        if final_best[(eval_metric, \"mean\")].any(): \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "            }\n",
    "\n",
    "            # Extract best runs: \n",
    "            best_params = {}\n",
    "            for col in sweeped_columns:\n",
    "                best_params[col] = final_best[(col, '')].item()\n",
    "            \n",
    "            hp_runs[dataset][model] = subset.copy()\n",
    "            \n",
    "            # Start with the entire DataFrame\n",
    "            filtered_subset = subset.copy()\n",
    "\n",
    "            # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "            for param, value in best_params.items():\n",
    "                filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "            best_runs[dataset][model] = filtered_subset\n",
    "        \n",
    "        else: \n",
    "            best_results[dataset][model] = {\n",
    "                \"mean\": np.nan,\n",
    "                \"std\": np.nan,\n",
    "            }\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "COLS = [\n",
    "    'dataset.parameters.data_seed',\n",
    "    'dataset.parameters.batch_size',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.feature_encoder.out_channels',\n",
    "    'model.readout.readout_name',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'model.optimizer.lr', \n",
    "    \n",
    "]\n",
    "\n",
    "a = hp_runs['US-county-demos-BirthRate']['scn'].sort_values(by=COLS, ascending=False)[COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in COLS:\n",
    "#     print(a[col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save obtained best results and best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Cora</th>\n",
       "      <th>MUTAG</th>\n",
       "      <th>NCI1</th>\n",
       "      <th>NCI109</th>\n",
       "      <th>PROTEINS</th>\n",
       "      <th>PubMed</th>\n",
       "      <th>US-county-demos-BachelorRate</th>\n",
       "      <th>US-county-demos-BirthRate</th>\n",
       "      <th>US-county-demos-DeathRate</th>\n",
       "      <th>US-county-demos-Election</th>\n",
       "      <th>US-county-demos-MedianIncome</th>\n",
       "      <th>US-county-demos-MigraRate</th>\n",
       "      <th>US-county-demos-UnemploymentRate</th>\n",
       "      <th>ZINC</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>roman_empire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sccn</th>\n",
       "      <td>80.86  2.16</td>\n",
       "      <td>70.64  5.9</td>\n",
       "      <td>75.27  1.74</td>\n",
       "      <td>75.31  1.36</td>\n",
       "      <td>75.05  2.76</td>\n",
       "      <td>88.37  0.48</td>\n",
       "      <td>0.3588  0.0246</td>\n",
       "      <td>0.8242  0.0942</td>\n",
       "      <td>0.5751  0.0553</td>\n",
       "      <td>0.5344  0.0323</td>\n",
       "      <td>0.2908  0.032</td>\n",
       "      <td>0.9146  0.1822</td>\n",
       "      <td>0.4328  0.044</td>\n",
       "      <td>0.4858  0.0584</td>\n",
       "      <td>69.6  1.83</td>\n",
       "      <td>89.07  0.25</td>\n",
       "      <td>88.27  0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sccnn_custom</th>\n",
       "      <td>82.19  1.07</td>\n",
       "      <td>76.17  6.63</td>\n",
       "      <td>76.6  1.75</td>\n",
       "      <td>77.12  1.07</td>\n",
       "      <td>74.19  2.86</td>\n",
       "      <td>88.18  0.32</td>\n",
       "      <td>0.3394  0.028</td>\n",
       "      <td>0.7937  0.1162</td>\n",
       "      <td>0.5527  0.0474</td>\n",
       "      <td>0.5112  0.0316</td>\n",
       "      <td>0.2825  0.0279</td>\n",
       "      <td>0.8976  0.1431</td>\n",
       "      <td>0.4278  0.0394</td>\n",
       "      <td>0.4088  0.0047</td>\n",
       "      <td>70.23  2.69</td>\n",
       "      <td>89.0  0.0</td>\n",
       "      <td>89.15  0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn</th>\n",
       "      <td>82.27  1.34</td>\n",
       "      <td>73.62  6.13</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>75.27  2.14</td>\n",
       "      <td>88.72  0.5</td>\n",
       "      <td>0.3186  0.0241</td>\n",
       "      <td>0.7122  0.0836</td>\n",
       "      <td>0.5208  0.0525</td>\n",
       "      <td>0.4648  0.043</td>\n",
       "      <td>0.2526  0.0247</td>\n",
       "      <td>0.9209  0.1993</td>\n",
       "      <td>0.3753  0.0432</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>71.24  1.68</td>\n",
       "      <td>nan  nan</td>\n",
       "      <td>nan  nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset               Cora         MUTAG          NCI1        NCI109      PROTEINS        PubMed US-county-demos-BachelorRate US-county-demos-BirthRate US-county-demos-DeathRate US-county-demos-Election US-county-demos-MedianIncome US-county-demos-MigraRate US-county-demos-UnemploymentRate             ZINC      citeseer   minesweeper  roman_empire\n",
       "Model                                                                                                                                                                                                                                                                                                                                                        \n",
       "sccn          80.86  2.16   70.64  5.9  75.27  1.74  75.31  1.36  75.05  2.76  88.37  0.48              0.3588  0.0246           0.8242  0.0942           0.5751  0.0553          0.5344  0.0323               0.2908  0.032           0.9146  0.1822                   0.4328  0.044  0.4858  0.0584   69.6  1.83  89.07  0.25  88.27  0.14\n",
       "sccnn_custom  82.19  1.07  76.17  6.63   76.6  1.75  77.12  1.07  74.19  2.86  88.18  0.32               0.3394  0.028           0.7937  0.1162           0.5527  0.0474          0.5112  0.0316              0.2825  0.0279           0.8976  0.1431                  0.4278  0.0394  0.4088  0.0047  70.23  2.69    89.0  0.0  89.15  0.32\n",
       "scn           82.27  1.34  73.62  6.13     nan  nan     nan  nan  75.27  2.14   88.72  0.5              0.3186  0.0241           0.7122  0.0836           0.5208  0.0525           0.4648  0.043              0.2526  0.0247           0.9209  0.1993                  0.3753  0.0432        nan  nan  71.24  1.68     nan  nan     nan  nan"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of allowed rows to display\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "result_dict.to_csv(f\"best_results_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate signal down comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique datasets\n",
    "datasets = list(df['dataset.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "hp_runs = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df[\n",
    "            (df['dataset.parameters.data_name'] == dataset)\n",
    "            & (df['model.model_name'] == model)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns, dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\"] for col in performance_columns}\n",
    "        )\n",
    "\n",
    "         # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(2)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "        if sorted(list(aggregated['model.readout.readout_name'].unique())) == sorted(['NoReadOut', 'PropagateSignalDown']):\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                agg_sub = aggregated[aggregated['model.readout.readout_name'] == prop_type]\n",
    "                agg_sub = agg_sub.sort_values(\n",
    "                    by=(optim_metric, \"mean\"), ascending=(direction == 'min')\n",
    "                )\n",
    "                \n",
    "                final_best = agg_sub.head(1)\n",
    "                if final_best[(eval_metric, \"mean\")].any(): \n",
    "                    best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                        \"mean\": final_best[(eval_metric, \"mean\")].values[0],\n",
    "                        \"std\": final_best[(eval_metric, \"std\")].values[0],\n",
    "                    }\n",
    "\n",
    "                    # Extract best runs: \n",
    "                    best_params = {}\n",
    "                    for col in sweeped_columns:\n",
    "                        best_params[col] = final_best[(col, '')].item()\n",
    "                    \n",
    "                    hp_runs[dataset][model] = subset.copy()\n",
    "                    \n",
    "                    # Start with the entire DataFrame\n",
    "                    filtered_subset = subset.copy()\n",
    "\n",
    "                    # Iterate over each key-value pair in the best parameters dictionary and filter the DataFrame\n",
    "                    for param, value in best_params.items():\n",
    "                        filtered_subset = filtered_subset[filtered_subset[param] == value]\n",
    "                    best_runs[dataset][model] = filtered_subset\n",
    "                \n",
    "                else: \n",
    "                    best_results[dataset][model] = {\n",
    "                        \"mean\": np.nan,\n",
    "                        \"std\": np.nan,\n",
    "                        \"prop_type\": prop_type\n",
    "                    }\n",
    "        else:\n",
    "            prop_types = ['NoReadOut', 'PropagateSignalDown']\n",
    "            for prop_type in prop_types:\n",
    "                best_results[dataset][f\"{model} ({prop_type})\"] = {\n",
    "                            \"mean\": np.nan,\n",
    "                            \"std\": np.nan,\n",
    "                        }\n",
    "\n",
    "       \n",
    "\n",
    "# Convert nested dictionary to DataFrame\n",
    "nested_dict = dict(best_results)\n",
    "result_dict = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (i, j): nested_dict[i][j]\n",
    "        for i in nested_dict\n",
    "        for j in nested_dict[i].keys()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "\n",
    "result_dict[\"performance\"] = result_dict.apply(\n",
    "    lambda x: f\"{x['mean']}  {x['std']}\", axis=1\n",
    ")\n",
    "result_dict = result_dict.drop([\"mean\", \"std\"], axis=1)\n",
    "\n",
    "# Reset multiindex\n",
    "result_dict = result_dict.reset_index()\n",
    "# rename columns\n",
    "result_dict.columns = [\"Dataset\", \"Model\", \"Performance\"]\n",
    "\n",
    "result_dict = result_dict.pivot_table(\n",
    "    index=\"Model\", columns=\"Dataset\", values=\"Performance\", aggfunc=\"first\"\n",
    ")\n",
    "result_dict.reset_index(inplace=True)\n",
    "\n",
    "result_dict['ReadOut'] = result_dict['Model'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "result_dict['Model'] = result_dict['Model'].apply(lambda x: x.split('(')[0])\n",
    "\n",
    "result_dict.sort_values(by=['Model','ReadOut'], inplace=True)\n",
    "\n",
    "columns = ['Model',\n",
    "'ReadOut',\n",
    " 'Cora',\n",
    " 'MUTAG',\n",
    " 'NCI1',\n",
    " 'NCI109',\n",
    " 'PROTEINS',\n",
    " 'PubMed',\n",
    " 'US-county-demos-BachelorRate',\n",
    " 'US-county-demos-BirthRate',\n",
    " 'US-county-demos-DeathRate',\n",
    " 'US-county-demos-Election',\n",
    " 'US-county-demos-MedianIncome',\n",
    " 'US-county-demos-MigraRate',\n",
    " 'US-county-demos-UnemploymentRate',\n",
    " 'ZINC',\n",
    " 'citeseer',\n",
    " 'minesweeper',\n",
    " 'roman_empire',]\n",
    "result_dict = result_dict[columns]\n",
    "result_dict.to_csv(f\"ablation_simplicial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
